{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: six in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from cycler>=0.10->matplotlib) (1.15.0)\n",
      "1.8.0\n",
      "Requirement already satisfied: torch==1.8.0 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (1.8.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from torch==1.8.0) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from torch==1.8.0) (1.19.5)\n",
      "Requirement already satisfied: opencv-python in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from opencv-python) (1.19.5)\n",
      "1.8.0\n",
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "!pip install torch==1.8.0\n",
    "!pip install opencv-python\n",
    "import cv2\n",
    "print(torch.__version__)\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np, numpy.linalg\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float64 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#class for forward pass and loss\n",
    "\n",
    "class custom_multiclass_torch(torch.nn.Module):\n",
    "    def __init__(self, N, P, C, K, f,a,b,c,beta, x_patches_train, x_patches_test):\n",
    "        super(custom_multiclass_torch, self).__init__()\n",
    "\n",
    "        \n",
    "        #initialize several variables \n",
    "        # parameters, N = number of images, K = number of patches, P = pooling size, C = output dimension, f = filter size\n",
    "\n",
    "        self.N = N\n",
    "        self.P = P\n",
    "        self.C = C \n",
    "        self.K = K\n",
    "        self.f = f \n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.beta = beta\n",
    "        self.x_patches_train = x_patches_train\n",
    "        self.x_patches_test = x_patches_test\n",
    "        \n",
    "        \n",
    "        #initialize tensor array variables as dictionaries\n",
    "        \n",
    "        self.Z_1_arr_train = nn.ParameterDict({  })\n",
    "        self.Z_1_arr_prime_train = nn.ParameterDict({})\n",
    "        self.Z_2_arr_train = nn.ParameterDict({})\n",
    "        self.Z_2_arr_prime_train = nn.ParameterDict({})\n",
    "        self.Z_4_arr_train = nn.ParameterDict({})\n",
    "        self.Z_4_arr_prime_train = nn.ParameterDict({})\n",
    "        self.Z_arr_train = {}\n",
    "        self.Z_arr_prime_train = {}\n",
    "        \n",
    "        # fill in dictionaries with Z1 Z2 Z4 tensor parameters\n",
    "        for i in range(1,K//P+1):\n",
    "            for j in range(1,C+1):\n",
    "                fan_in = f+1\n",
    "\n",
    "                self.Z_1_arr_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((3*f**2,3*f**2), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_1_arr_prime_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((3*f**2,3*f**2), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_2_arr_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((3*f**2,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_2_arr_prime_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((3*f**2,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_4_arr_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((1,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_4_arr_prime_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((1,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                \n",
    "                self.Z_arr_train[str(i)+','+str(j)] = torch.vstack((torch.hstack((self.Z_1_arr_train[str(i)+','+str(j)], self.Z_2_arr_train[str(i)+','+str(j)])), torch.hstack((torch.transpose(self.Z_2_arr_train[str(i)+','+str(j)], 0, 1),self.Z_4_arr_train[str(i)+','+str(j)]))))\n",
    "                self.Z_arr_prime_train[str(i)+','+str(j)] = torch.vstack((torch.hstack((self.Z_1_arr_prime_train[str(i)+','+str(j)], self.Z_2_arr_prime_train[str(i)+','+str(j)])), torch.hstack((torch.transpose(self.Z_2_arr_prime_train[str(i)+','+str(j)], 0, 1),self.Z_4_arr_prime_train[str(i)+','+str(j)]))))\n",
    "                \n",
    "\n",
    "    def forward(self, i):\n",
    "        \n",
    "        Z_1_new = {}\n",
    "        Z_2_new = {}\n",
    "        Z_4_new = {}\n",
    "        Z_1_prime_new = {}\n",
    "        Z_2_prime_new = {}\n",
    "        Z_4_prime_new = {}\n",
    "        Z_new = {} \n",
    "        Z_new_prime = {}\n",
    "        \n",
    "        \n",
    "     \n",
    "        #transform Z matrices into positve-semidefinite matrices\n",
    "        \n",
    "        #convertTo = \"positive semidefinite\"\n",
    "        convertTo = \"other\"\n",
    "        for key in self.Z_arr_train:\n",
    "            if convertTo == \"positive semidefinite\":\n",
    "                Z_new[key] = torch.matmul(self.Z_arr_train[key], self.Z_arr_train[key].T)+torch.eye(3*f**2+1)\n",
    "            elif convertTo == \"symmetric:\":\n",
    "                Z_new[key] = 0.5 * (self.Z_arr_train[key]+self.Z_arr_train[key].T)\n",
    "            else:\n",
    "                Z_new[key] = self.Z_arr_train[key]\n",
    "            Z_1_new[key] = Z_new[key][:3*f**2,:3*f**2]\n",
    "            Z_2_new[key] = Z_new[key][3*f**2,:3*f**2]\n",
    "            Z_4_new[key] = Z_new[key][3*f**2,3*f**2]\n",
    "            \n",
    "        for key in self.Z_arr_prime_train:\n",
    "            if convertTo == \"positive semidefinite\":\n",
    "                Z_new_prime[key] = torch.matmul(self.Z_arr_prime_train[key], self.Z_arr_prime_train[key].T)+torch.eye(3*f**2+1)\n",
    "            elif convertTo == \"symmetric\":\n",
    "                Z_new_prime[key] = 0.5 * (self.Z_arr_prime_train[key] + self.Z_arr_prime_train[key].T)\n",
    "            else:\n",
    "                Z_new_prime[key] = self.Z_arr_prime_train[key]\n",
    "            Z_1_prime_new[key] = Z_new_prime[key][:3*f**2,:3*f**2]\n",
    "            Z_2_prime_new[key] = Z_new_prime[key][3*f**2,:3*f**2]\n",
    "            Z_4_prime_new[key] = Z_new_prime[key][3*f**2,3*f**2]\n",
    "        \n",
    "    \n",
    "        print(self.Z_1_arr_train[\"1,2\"])\n",
    "        print(self.Z_4_arr_train[\"1,2\"])\n",
    "\n",
    "        \n",
    "        ypred = torch.zeros((C))\n",
    "\n",
    "        \n",
    "        # performing calculations for ypred scores \n",
    "        for t in range(1,C+1):\n",
    "            \n",
    "            constant_part = 0\n",
    "            for k in range(1,K//P+1):\n",
    "                constant_part += Z_4_new[str(k)+\",\"+str(t)] - Z_4_prime_new[str(k)+\",\"+str(t)]\n",
    "            constant_part *= c\n",
    "\n",
    "            linear_part = 0\n",
    "            for k in range(1,K//P+1):\n",
    "                for l in range(1,P+1):\n",
    "                    linear_part += torch.matmul(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0,1),(Z_2_new[str(k)+\",\"+str(t)] - Z_2_prime_new[str(k)+\",\"+str(t)]))\n",
    "            linear_part *= b/P\n",
    "\n",
    "            quadratic_part = 0\n",
    "            for k in range(1,K//P+1):\n",
    "                for l in range(1,P+1):\n",
    "                    newpart = torch.matmul(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0, 1),(Z_1_new[str(k)+\",\"+str(t)] - Z_1_prime_new[str(k)+\",\"+str(t)]))\n",
    "                    newpart = torch.matmul(newpart, self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2],1))\n",
    "                    quadratic_part += newpart\n",
    "            quadratic_part *= a/P\n",
    "            \n",
    "            #print(quadratic_part, linear_part, constant_part)\n",
    "            \n",
    "            \n",
    "         \n",
    "            ypred[t-1] = quadratic_part + linear_part + constant_part\n",
    "\n",
    "\n",
    "        return ypred\n",
    "\n",
    "    \n",
    "    \n",
    "    def customloss(self, Yhat, y):\n",
    "        #convex L2 loss function\n",
    "        objective1 = 0.5 * torch.norm(Yhat - y)**2 *N/y.shape[0]\n",
    "        \n",
    "\n",
    "        # sum of Z4 scalars added to loss\n",
    "        objective2 = 0 \n",
    "\n",
    "        for i in range(1,K//P+1):\n",
    "            for j in range(1,C+1):\n",
    "                objective2 += self.Z_4_arr_train[str(i)+\",\"+str(j)] + self.Z_4_arr_prime_train[str(i)+\",\"+str(j)]\n",
    "            \n",
    "        objective = objective1+objective2\n",
    "\n",
    "        return objective\n",
    "            \n",
    "                  \n",
    "\n",
    "                    \n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K:  64\n",
      "N:  1000\n",
      "patches_train size:  torch.Size([1000, 64, 48])\n",
      "patches_val size:  torch.Size([100, 64, 48])\n",
      "patches_test size:  torch.Size([100, 64, 48])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load cifar data\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "#subset data\n",
    "X_train = X_train[:1000,:,:,:]\n",
    "y_train = y_train[:1000]\n",
    "X_test = X_test[:200,:,:,:]\n",
    "y_test = y_test[:200]\n",
    "\n",
    "#set up val/test split\n",
    "X_val = X_test[:X_test.shape[0]//2,:,:,:]\n",
    "X_test = X_test[X_test.shape[0]//2:,:,:,:]\n",
    "\n",
    "y_val = y_test[:y_test.shape[0]//2,:]\n",
    "y_test = y_test[:y_test.shape[0]//2,:]\n",
    "\n",
    "\n",
    "#parameters: f is filter size, P is pooling size, C is class count, a,b,c are the polynomial activation constants\n",
    "\n",
    "f = 4\n",
    "\n",
    "\n",
    "\n",
    "train_images = X_train.astype(np.float64)\n",
    "train_labels = y_train.astype(np.float64)\n",
    "test_images = X_test.astype(np.float64)\n",
    "test_labels = y_test.astype(np.float64)\n",
    "val_images = X_val.astype(np.float64)\n",
    "val_labels = y_val.astype(np.float64)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #meaning out the images\n",
    "# mean_image = np.mean(train_images, axis = 0)\n",
    "# train_images -= mean_image\n",
    "# test_images -= mean_image\n",
    "# val_images -= mean_image\n",
    "\n",
    "# # RGB 0 to 255\n",
    "# #-127.5 to +127.5\n",
    "# #-1 to 1\n",
    "\n",
    "# # scale to [-1, 1]\n",
    "\n",
    "# train_images /= 127.5\n",
    "# test_images /= 127.5\n",
    "# val_images /= 127.5\n",
    "\n",
    "\n",
    "train_images /= 255\n",
    "#train_images *= 2\n",
    "#train_images -= 1\n",
    "\n",
    "test_images /= 255\n",
    "#test_images *= 2\n",
    "#test_images -= 1\n",
    "\n",
    "val_images /= 255\n",
    "#val_images *= 2\n",
    "#val_images -= 1\n",
    "\n",
    "train_images_v2 = np.swapaxes(train_images.reshape(train_images.shape[0], 3, 32, 32), 2, 3)\n",
    "test_images_v2 = np.swapaxes(test_images.reshape(test_images.shape[0], 3, 32, 32), 2, 3)\n",
    "val_images_v2 = np.swapaxes(val_images.reshape(val_images.shape[0],3, 32, 32), 2, 3)\n",
    "\n",
    "#setting up patches\n",
    "patches_train = torch.nn.functional.unfold(torch.tensor(train_images_v2), kernel_size=(f,f), stride=f, padding=0)\n",
    "patches_test = torch.nn.functional.unfold(torch.tensor(test_images_v2), kernel_size=(f, f), stride=f, padding=0)\n",
    "patches_val = torch.nn.functional.unfold(torch.tensor(val_images_v2), kernel_size=(f,f), stride=f, padding=0)\n",
    "\n",
    "\n",
    "patches_train = patches_train.permute(0,2,1)\n",
    "patches_test = patches_test.permute(0,2,1)\n",
    "patches_val = patches_val.permute(0,2,1)\n",
    "\n",
    "N = X_train.shape[0]\n",
    "K = patches_train.shape[1]\n",
    "\n",
    "Yhat_train =  None\n",
    "Yhat_test = None\n",
    "\n",
    "P = K\n",
    "C = 10\n",
    "a=0.09\n",
    "b=0.5\n",
    "c=0.47\n",
    "beta = 1e-6\n",
    "\n",
    "print(\"K: \", K)\n",
    "print(\"N: \", N)\n",
    "print(\"patches_train size: \", patches_train.size())\n",
    "print(\"patches_val size: \", patches_val.size())\n",
    "print(\"patches_test size: \", patches_test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, epochs=1):\n",
    "    model = model.to(device=device) # move the model parameters to CPU/GPU\n",
    "    \n",
    "    loss_train = []\n",
    "    accuracies_train = []\n",
    "    accuracies_val = []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(zip(train_images, train_labels)):\n",
    "            model.train() # put model to training mode\n",
    "\n",
    "            scores = model(t)\n",
    "            \n",
    "      \n",
    "\n",
    "            y_hot = torch.zeros(scores.size(), dtype = dtype)\n",
    "            \n",
    "            y_hot[y] = 1\n",
    "            \n",
    "\n",
    "\n",
    "            loss = loss_fn(scores, y_hot)\n",
    "            loss_train.append(loss)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 100 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                accuracies_train.append(check_accuracy(X_train, y_train, model, segment = \"train\"))\n",
    "                \n",
    "                accuracies_val.append(check_accuracy(X_val, y_val, model, segment = \"val\"))\n",
    "                \n",
    "\n",
    "    return loss_train, accuracies_train, accuracies_val\n",
    "\n",
    "                \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(X, Y, model, segment = \"train\"):\n",
    "    if segment=='train':\n",
    "        print('Checking accuracy on train set')\n",
    "    elif segment == \"val\":\n",
    "        print('Checking accuracy on val set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(zip(X, Y)):\n",
    "            scores = model(t)\n",
    "            max_score_idx = torch.argmax(scores)\n",
    "            y = torch.tensor(y)\n",
    "            print(scores, y)\n",
    "            addvalue = 1 if (max_score_idx == y) else 0\n",
    "            num_correct += addvalue\n",
    "            num_samples += 1\n",
    "            \n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)'% (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_multiclass_torch(N, P, C, K, f,a,b,c,beta, patches_train, patches_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for param in model.parameters():\n",
    "    #print(param.shape)\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.8907, -0.6682,  0.8294,  ..., -0.3283, -0.1726,  1.2581],\n",
      "        [-2.0239,  0.1107,  0.0067,  ..., -1.0406, -1.8674, -0.1110],\n",
      "        [ 1.5277,  2.7141,  0.3903,  ..., -0.7939,  2.4227,  0.2194],\n",
      "        ...,\n",
      "        [-0.3398,  0.6941,  0.0763,  ..., -0.3218,  0.6683,  0.9873],\n",
      "        [ 1.9783,  1.8039, -0.2071,  ...,  0.5478, -0.3675,  0.1147],\n",
      "        [ 0.9563, -0.6527, -0.1232,  ..., -0.4529, -1.6135, -1.1644]],\n",
      "       dtype=torch.float64, requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.7556]], dtype=torch.float64, requires_grad=True)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'custom_multiclass_torch' object has no attribute 'Z_1_prime_arr_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fa9fb671ff4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-73ff09861b24>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimizer, epochs)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# put model to training mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envtorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-310407db5895>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0mnewpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_patches_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_patches_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ_1_arr_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ_1_prime_arr_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                     \u001b[0mnewpart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_patches_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_patches_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mquadratic_part\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnewpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/envtorch/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    948\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'custom_multiclass_torch' object has no attribute 'Z_1_prime_arr_train'"
     ]
    }
   ],
   "source": [
    "loss_fn = model.customloss\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "loss_train, accuracies_train, accuracies_val = train(model, loss_fn, optimizer, epochs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Training Accuracy')\n",
    "#print(accuracies_train)\n",
    "plt.plot(accuracies_train)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val Accuracy')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Validation Accuracy')\n",
    "#print(accuracies_val)\n",
    "plt.plot(accuracies_val)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val Accuracy')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Training Loss')\n",
    "#print(loss_train)\n",
    "plt.plot(loss_train)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_accuracy(X_test, y_test, model, segment = \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
