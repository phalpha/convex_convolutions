{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "Requirement already satisfied: torch==1.8.0 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from torch==1.8.0) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from torch==1.8.0) (3.7.4.3)\n",
      "Requirement already satisfied: opencv-python in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from opencv-python) (1.19.5)\n",
      "1.8.0\n",
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "print(torch.__version__)\n",
    "!pip install torch==1.8.0\n",
    "!pip install opencv-python\n",
    "import cv2\n",
    "print(torch.__version__)\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float64 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAIN = 49000\n",
    "\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# and for performing data augmentation; here we set up a transform to\n",
    "# preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# standard deviation of each RGB value; we've hardcoded the mean and std.\n",
    "transform = T.Compose([\n",
    "                T.ToTensor(),\n",
    "                T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "            ])\n",
    "\n",
    "# We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# training set into train and val sets by passing a Sampler object to the\n",
    "# DataLoader telling how it should sample from the underlying Dataset.\n",
    "cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                             transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "                           transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True, \n",
    "                            transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters, K = number of patches, P = pooling size, C = output dimension, f = filter size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class custom_multiclass_torch(torch.nn.Module):\n",
    "    def __init__(self, N, P, C, K, f,a,b,c,beta, x_patches_train, x_patches_test):\n",
    "        super(custom_multiclass_torch, self).__init__()\n",
    "\n",
    "        self.N = N\n",
    "        self.P = P\n",
    "        self.C = C \n",
    "        self.K = K\n",
    "        self.f = f \n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.beta = beta\n",
    "        self.x_patches_train = x_patches_train\n",
    "        self.x_patches_test = x_patches_test\n",
    "        #initialize tensor array variables\n",
    "\n",
    "#         self.Z_1_arr_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_1_arr_prime_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_2_arr_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_2_arr_prime_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_4_arr_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_4_arr_prime_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "\n",
    "#         self.Z_arr_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_arr_prime_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "        \n",
    "        #print(len(self.Z_1_arr_train))\n",
    "        # set random weights using kaising normalization\n",
    "        \n",
    "        self.Z_1_arr_train = nn.ParameterDict({  })\n",
    "        self.Z_1_arr_prime_train = nn.ParameterDict({})\n",
    "        self.Z_2_arr_train = nn.ParameterDict({})\n",
    "        self.Z_2_arr_prime_train = nn.ParameterDict({})\n",
    "        self.Z_4_arr_train = nn.ParameterDict({})\n",
    "        self.Z_4_arr_prime_train = nn.ParameterDict({})\n",
    "        self.Z_arr_train = {}\n",
    "        self.Z_arr_prime_train = {}\n",
    "        self.x_patches_train = x_patches_train\n",
    "        self.x_patches_test = x_patches_test\n",
    "        for i in range(1,K//P+1):\n",
    "            for j in range(1,C+1):\n",
    "                fan_in = f+1\n",
    "                #w = torch.randn((f+1,f+1), device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "                #w.requires_grad = True\n",
    "                #Z_arr[i][j] = w\n",
    "                #w2 = torch.randn((f+1,f+1), device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "                #w2.requires_grad = True\n",
    "                #Z_arr_prime_train[i][j] = w2 \n",
    "\n",
    "                #self.test = torch.nn.Parameter(data = torch.randn((f,f), device = device, dtype = dtype), requires_grad = True)\n",
    "#                 self.Z_1_arr_train[i][j] =  torch.nn.Parameter(data = torch.randn((f,f)).to(device), requires_grad = True) \n",
    "#                 self.Z_2_arr_train[i][j]  = torch.nn.Parameter(data = torch.randn((f,1)).to(device),  requires_grad = True) \n",
    "#                 self.Z_4_arr_train[i][j] = torch.nn.Parameter(data = torch.randn((1,1)).to(device),  requires_grad = True) \n",
    "\n",
    "#                 self.Z_1_arr_prime_train[i][j] = torch.nn.Parameter(data =torch.randn((f,f)).to(device),  requires_grad = True) \n",
    "#                 self.Z_2_arr_prime_train[i][j]  = torch.nn.Parameter(data =torch.randn((f,1)).to(device),  requires_grad = True) \n",
    "#                 self.Z_4_arr_prime_train[i][j] = torch.nn.Parameter(data = torch.randn((1,1)).to(device),  requires_grad = True) \n",
    "\n",
    "                \n",
    "#                 self.Z_arr_train[i][j] = torch.vstack((torch.hstack((self.Z_1_arr_train[i][j], self.Z_2_arr_train[i][j])), torch.hstack((torch.transpose(self.Z_2_arr_train[i][j], 0, 1),self.Z_4_arr_train[i][j]))))\n",
    "#                 self.Z_arr_prime_train[i][j] = torch.vstack((torch.hstack((self.Z_1_arr_prime_train[i][j], self.Z_2_arr_prime_train[i][j])), torch.hstack((torch.transpose(self.Z_2_arr_prime_train[i][j], 0, 1),self.Z_4_arr_prime_train[i][j]))))\n",
    "\n",
    "                self.Z_1_arr_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((f,f), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_1_arr_prime_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((f,f), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_2_arr_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((f,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_2_arr_prime_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((f,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_4_arr_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((1,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_4_arr_prime_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.randn((1,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                \n",
    "                self.Z_arr_train[str(i)+','+str(j)] = torch.vstack((torch.hstack((self.Z_1_arr_train[str(i)+','+str(j)], self.Z_2_arr_train[str(i)+','+str(j)])), torch.hstack((torch.transpose(self.Z_2_arr_train[str(i)+','+str(j)], 0, 1),self.Z_4_arr_train[str(i)+','+str(j)]))))\n",
    "                self.Z_arr_prime_train[str(i)+','+str(j)] = torch.vstack((torch.hstack((self.Z_1_arr_prime_train[str(i)+','+str(j)], self.Z_2_arr_prime_train[str(i)+','+str(j)])), torch.hstack((torch.transpose(self.Z_2_arr_prime_train[str(i)+','+str(j)], 0, 1),self.Z_4_arr_prime_train[str(i)+','+str(j)]))))\n",
    "\n",
    "               \n",
    "    #self.Z_1_arr_train = torch.Tensor(self.Z_1_arr_train)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.Z_arr_train = torch.vstack((torch.hstack((self.Z_1_arr_train, self.Z_2_arr_train), torch.hstack(torch.transpose(self.Z_2_arr_train),self.Z_4_arr_train))))\n",
    "        #self.Z_arr_prime_train = torch.vstack((torch.hstack((self.Z_1_arr_prime_train, self.Z_2_arr_prime_train), torch.hstack(torch.transpose(self.Z_2_arr_prime_train),self.Z_4_prime_arr_train))))\n",
    "\n",
    "    def forward(self, i):\n",
    "        ypred = torch.zeros((C))\n",
    "        print(\"index\", i)\n",
    "        for t in range(1,C+1):\n",
    "            constant_part = 0\n",
    "            for k in range(1,K//P+1):\n",
    "                constant_part += self.Z_4_arr_train[str(k)+\",\"+str(t)] - self.Z_4_arr_prime_train[str(k)+\",\"+str(t)]\n",
    "\n",
    "            constant_part *= c\n",
    "\n",
    "            linear_part = 0\n",
    "            for k in range(1,K//P+1):\n",
    "                for l in range(1,P+1):\n",
    "                   # print(x_patches[i][(k-1)*P+ l].shape)\n",
    "                    linear_part += torch.matmul(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0,1),(self.Z_2_arr_train[str(k)+\",\"+str(t)] - self.Z_2_arr_prime_train[str(k)+\",\"+str(t)]))\n",
    "                    #print((k-1)*P+ l-1, self.x_patches_train[i][(k-1)*P+ l-1].size(), self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1).size())\n",
    "            linear_part *= b//P\n",
    "\n",
    "            quadratic_part = 0\n",
    "            for k in range(1,K//P+1):\n",
    "                for l in range(1,P+1):\n",
    "                    newpart = torch.matmul(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0, 1),(self.Z_1_arr_train[str(k)+\",\"+str(t)] - self.Z_1_arr_prime_train[str(k)+\",\"+str(t)]))\n",
    "                    newpart = torch.matmul(newpart, self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2],1))\n",
    "                    quadratic_part += newpart\n",
    "                    #print(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0, 1).size())\n",
    "                    #print(\"second part\")\n",
    "                    #print((self.Z_1_arr_train[str(k)+\",\"+str(t)] - self.Z_1_arr_prime_train[str(k)+\",\"+str(t)]).size())\n",
    "                    #print(\"third\")\n",
    "                    #print(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2],1).size())\n",
    "            quadratic_part *= a//P\n",
    "            \n",
    "            #print(quadratic_part, linear_part, constant_part)\n",
    "\n",
    "            ypred[t-1] = quadratic_part + linear_part + constant_part\n",
    "        #print(ypred)\n",
    "\n",
    "        return ypred\n",
    "\n",
    "    \n",
    "    \n",
    "    def customloss(self, Yhat, y):\n",
    "         #loss = nn.MSELoss()\n",
    "        #objective1 = loss(Yhat, Y)\n",
    "        objective1 = 0.5 * torch.norm(Yhat - y)**2 *N/y.shape[0]\n",
    "\n",
    "        objective2 = 0 \n",
    "\n",
    "        for i in range(1,K//P+1):\n",
    "            for j in range(1,C+1):\n",
    "                objective2 += self.Z_4_arr_train[str(i)+\",\"+str(j)] + self.Z_4_arr_prime_train[str(i)+\",\"+str(j)]\n",
    "            \n",
    "        objective = objective1+objective2\n",
    "\n",
    "        return objective\n",
    "            \n",
    "                  \n",
    "\n",
    "                    \n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 32, 32) (10000, 1, 32, 32)\n",
      "torch.Size([50000, 256, 4])\n",
      "256 2 10\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#X_val = X_test[:X_test.shape[0]//2,:,:,:]\n",
    "#X_test = X_test[x_test.shape[0]//2,:,:,:]\n",
    "\n",
    "\n",
    "f = 4\n",
    "P = 2\n",
    "C = 10\n",
    "a,b,c = 1,2,3\n",
    "beta = 1\n",
    "\n",
    "X_train = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_train])\n",
    "X_test = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_test])\n",
    "\n",
    "\n",
    "#[1 by 4] times [4 by 4] times [4 by 1] = [1 by 1] (scalar)\n",
    "\n",
    "train_images = X_train.astype(np.float64)\n",
    "train_labels = y_train.astype(np.float64)\n",
    "test_images = X_test.astype(np.float64)\n",
    "test_labels = y_test.astype(np.float64)\n",
    "\n",
    "train_images_v2 = np.swapaxes(train_images.reshape(train_images.shape[0], 1, 32, 32), 2, 3)\n",
    "test_images_v2 = np.swapaxes(test_images.reshape(test_images.shape[0], 1, 32, 32), 2, 3)\n",
    "print(train_images_v2.shape, test_images_v2.shape)\n",
    "patches_train = torch.nn.functional.unfold(torch.tensor(train_images_v2), kernel_size=(2,2), stride=2, padding=0)\n",
    "patches_test = torch.nn.functional.unfold(torch.tensor(test_images_v2), kernel_size=(2,2), stride=2, padding=0)\n",
    "patches_train = patches_train.permute(0,2,1)\n",
    "patches_test = patches_test.permute(0,2,1)\n",
    "\n",
    "print(patches_train.shape)\n",
    "N = X_train.shape[0]\n",
    "K = patches_train.shape[1]\n",
    "\n",
    "print(K, P, C)\n",
    "Yhat_train =  None\n",
    "Yhat_test = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, epochs=1):\n",
    "    model = model.to(device=device) # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        print(train_labels.shape)\n",
    "        for t, (x, y) in enumerate(zip(train_images, train_labels)):\n",
    "            model.train() # put model to training mode\n",
    "            #x = x.to(device=device, dtype=dtype) # move to device, e.g. GPU\n",
    "            #y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(t)\n",
    "            \n",
    "            # print(scores.shape)\n",
    "            # input()\n",
    "\n",
    "            #loss = F.cross_entropy(scores, y)\n",
    "            y_hot = torch.zeros(scores.size(), dtype = dtype)\n",
    "            \n",
    "            y_hot[y] = 1\n",
    "            \n",
    "            #currect class = 4\n",
    "            #0 0 0 0 1\n",
    "            \n",
    "            #0.1 0.5 0.4\n",
    "            #0 0 1\n",
    "            #1\n",
    "            #print(scores, y_hot)\n",
    "\n",
    "            loss = loss_fn(scores, y_hot)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 10 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                #check_accuracy_part34(loader_val, model)\n",
    "                print()\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_multiclass_torch(N, P, C, K, f,a,b,c,beta, patches_train, patches_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7680\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for param in model.parameters():\n",
    "    #print(param.shape)\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n",
      "index 0\n",
      "Iteration 0, loss = 1338598839553.8264\n",
      "\n",
      "index 1\n",
      "index 2\n",
      "index 3\n",
      "index 4\n",
      "index 5\n",
      "index 6\n",
      "index 7\n",
      "index 8\n",
      "index 9\n",
      "index 10\n",
      "Iteration 10, loss = 745756847112.2577\n",
      "\n",
      "index 11\n",
      "index 12\n",
      "index 13\n",
      "index 14\n",
      "index 15\n",
      "index 16\n",
      "index 17\n",
      "index 18\n",
      "index 19\n",
      "index 20\n",
      "Iteration 20, loss = 3677871901291.8721\n",
      "\n",
      "index 21\n",
      "index 22\n",
      "index 23\n",
      "index 24\n",
      "index 25\n",
      "index 26\n",
      "index 27\n",
      "index 28\n",
      "index 29\n",
      "index 30\n",
      "Iteration 30, loss = 1757126527664.7651\n",
      "\n",
      "index 31\n",
      "index 32\n",
      "index 33\n",
      "index 34\n",
      "index 35\n",
      "index 36\n",
      "index 37\n",
      "index 38\n",
      "index 39\n",
      "index 40\n",
      "Iteration 40, loss = 1523409128372.3225\n",
      "\n",
      "index 41\n",
      "index 42\n",
      "index 43\n",
      "index 44\n",
      "index 45\n",
      "index 46\n",
      "index 47\n",
      "index 48\n",
      "index 49\n",
      "index 50\n",
      "Iteration 50, loss = 800849816611.7728\n",
      "\n",
      "index 51\n",
      "index 52\n",
      "index 53\n",
      "index 54\n",
      "index 55\n",
      "index 56\n",
      "index 57\n",
      "index 58\n",
      "index 59\n",
      "index 60\n",
      "Iteration 60, loss = 2182713254607.7725\n",
      "\n",
      "index 61\n",
      "index 62\n",
      "index 63\n",
      "index 64\n",
      "index 65\n",
      "index 66\n",
      "index 67\n",
      "index 68\n",
      "index 69\n",
      "index 70\n",
      "Iteration 70, loss = 1281428656493.7773\n",
      "\n",
      "index 71\n",
      "index 72\n",
      "index 73\n",
      "index 74\n",
      "index 75\n",
      "index 76\n",
      "index 77\n",
      "index 78\n",
      "index 79\n",
      "index 80\n",
      "Iteration 80, loss = 1320334405515.0864\n",
      "\n",
      "index 81\n",
      "index 82\n",
      "index 83\n",
      "index 84\n",
      "index 85\n",
      "index 86\n",
      "index 87\n",
      "index 88\n",
      "index 89\n",
      "index 90\n",
      "Iteration 90, loss = 2044417508054.2986\n",
      "\n",
      "index 91\n",
      "index 92\n",
      "index 93\n",
      "index 94\n",
      "index 95\n",
      "index 96\n",
      "index 97\n",
      "index 98\n",
      "index 99\n",
      "index 100\n",
      "Iteration 100, loss = 2888412187862.5850\n",
      "\n",
      "index 101\n",
      "index 102\n",
      "index 103\n",
      "index 104\n",
      "index 105\n",
      "index 106\n",
      "index 107\n",
      "index 108\n",
      "index 109\n",
      "index 110\n",
      "Iteration 110, loss = 1320675974277.1482\n",
      "\n",
      "index 111\n",
      "index 112\n",
      "index 113\n",
      "index 114\n",
      "index 115\n",
      "index 116\n",
      "index 117\n",
      "index 118\n",
      "index 119\n",
      "index 120\n",
      "Iteration 120, loss = 1629961582340.3298\n",
      "\n",
      "index 121\n",
      "index 122\n",
      "index 123\n",
      "index 124\n",
      "index 125\n",
      "index 126\n",
      "index 127\n",
      "index 128\n",
      "index 129\n",
      "index 130\n",
      "Iteration 130, loss = 1096082502272.4263\n",
      "\n",
      "index 131\n",
      "index 132\n",
      "index 133\n",
      "index 134\n",
      "index 135\n",
      "index 136\n",
      "index 137\n",
      "index 138\n",
      "index 139\n",
      "index 140\n",
      "Iteration 140, loss = 2066889495607.3962\n",
      "\n",
      "index 141\n",
      "index 142\n",
      "index 143\n",
      "index 144\n",
      "index 145\n",
      "index 146\n",
      "index 147\n",
      "index 148\n",
      "index 149\n",
      "index 150\n",
      "Iteration 150, loss = 554532877289.0957\n",
      "\n",
      "index 151\n",
      "index 152\n",
      "index 153\n",
      "index 154\n",
      "index 155\n",
      "index 156\n",
      "index 157\n",
      "index 158\n",
      "index 159\n",
      "index 160\n",
      "Iteration 160, loss = 3210387503809.9731\n",
      "\n",
      "index 161\n",
      "index 162\n",
      "index 163\n",
      "index 164\n",
      "index 165\n",
      "index 166\n",
      "index 167\n",
      "index 168\n",
      "index 169\n",
      "index 170\n",
      "Iteration 170, loss = 915234357643.9233\n",
      "\n",
      "index 171\n",
      "index 172\n",
      "index 173\n",
      "index 174\n",
      "index 175\n",
      "index 176\n",
      "index 177\n",
      "index 178\n",
      "index 179\n",
      "index 180\n",
      "Iteration 180, loss = 537481438563.5424\n",
      "\n",
      "index 181\n",
      "index 182\n",
      "index 183\n",
      "index 184\n",
      "index 185\n",
      "index 186\n",
      "index 187\n",
      "index 188\n",
      "index 189\n",
      "index 190\n",
      "Iteration 190, loss = 1404906605188.0854\n",
      "\n",
      "index 191\n",
      "index 192\n",
      "index 193\n",
      "index 194\n",
      "index 195\n",
      "index 196\n",
      "index 197\n",
      "index 198\n",
      "index 199\n",
      "index 200\n",
      "Iteration 200, loss = 626641610750.5192\n",
      "\n",
      "index 201\n",
      "index 202\n",
      "index 203\n",
      "index 204\n",
      "index 205\n",
      "index 206\n",
      "index 207\n",
      "index 208\n",
      "index 209\n",
      "index 210\n",
      "Iteration 210, loss = 1095904176056.8480\n",
      "\n",
      "index 211\n",
      "index 212\n",
      "index 213\n",
      "index 214\n",
      "index 215\n",
      "index 216\n",
      "index 217\n",
      "index 218\n",
      "index 219\n",
      "index 220\n",
      "Iteration 220, loss = 482439292662.9946\n",
      "\n",
      "index 221\n",
      "index 222\n",
      "index 223\n",
      "index 224\n",
      "index 225\n",
      "index 226\n",
      "index 227\n",
      "index 228\n",
      "index 229\n",
      "index 230\n",
      "Iteration 230, loss = 631201323752.6774\n",
      "\n",
      "index 231\n",
      "index 232\n",
      "index 233\n",
      "index 234\n",
      "index 235\n",
      "index 236\n",
      "index 237\n",
      "index 238\n",
      "index 239\n",
      "index 240\n",
      "Iteration 240, loss = 2264038702813.0928\n",
      "\n",
      "index 241\n",
      "index 242\n",
      "index 243\n",
      "index 244\n",
      "index 245\n",
      "index 246\n",
      "index 247\n",
      "index 248\n",
      "index 249\n",
      "index 250\n",
      "Iteration 250, loss = 466513854390.1053\n",
      "\n",
      "index 251\n",
      "index 252\n",
      "index 253\n",
      "index 254\n",
      "index 255\n",
      "index 256\n",
      "index 257\n",
      "index 258\n",
      "index 259\n",
      "index 260\n",
      "Iteration 260, loss = 657890551601.2502\n",
      "\n",
      "index 261\n",
      "index 262\n",
      "index 263\n",
      "index 264\n",
      "index 265\n",
      "index 266\n",
      "index 267\n",
      "index 268\n",
      "index 269\n",
      "index 270\n",
      "Iteration 270, loss = 1699955423739.4492\n",
      "\n",
      "index 271\n",
      "index 272\n",
      "index 273\n",
      "index 274\n",
      "index 275\n",
      "index 276\n",
      "index 277\n",
      "index 278\n",
      "index 279\n",
      "index 280\n",
      "Iteration 280, loss = 1522217961169.1155\n",
      "\n",
      "index 281\n",
      "index 282\n",
      "index 283\n",
      "index 284\n",
      "index 285\n",
      "index 286\n",
      "index 287\n",
      "index 288\n",
      "index 289\n",
      "index 290\n",
      "Iteration 290, loss = 1229627024224.3633\n",
      "\n",
      "index 291\n",
      "index 292\n",
      "index 293\n",
      "index 294\n",
      "index 295\n",
      "index 296\n",
      "index 297\n",
      "index 298\n",
      "index 299\n",
      "index 300\n",
      "Iteration 300, loss = 425186076330.6874\n",
      "\n",
      "index 301\n",
      "index 302\n",
      "index 303\n",
      "index 304\n",
      "index 305\n",
      "index 306\n",
      "index 307\n",
      "index 308\n",
      "index 309\n",
      "index 310\n",
      "Iteration 310, loss = 1305827071695.7217\n",
      "\n",
      "index 311\n",
      "index 312\n",
      "index 313\n",
      "index 314\n",
      "index 315\n",
      "index 316\n",
      "index 317\n",
      "index 318\n",
      "index 319\n",
      "index 320\n",
      "Iteration 320, loss = 344903528630.0176\n",
      "\n",
      "index 321\n",
      "index 322\n",
      "index 323\n",
      "index 324\n",
      "index 325\n",
      "index 326\n",
      "index 327\n",
      "index 328\n",
      "index 329\n",
      "index 330\n",
      "Iteration 330, loss = 408470964754.4984\n",
      "\n",
      "index 331\n",
      "index 332\n",
      "index 333\n",
      "index 334\n",
      "index 335\n",
      "index 336\n",
      "index 337\n",
      "index 338\n",
      "index 339\n",
      "index 340\n",
      "Iteration 340, loss = 751463094979.6715\n",
      "\n",
      "index 341\n",
      "index 342\n",
      "index 343\n",
      "index 344\n",
      "index 345\n",
      "index 346\n",
      "index 347\n",
      "index 348\n",
      "index 349\n",
      "index 350\n",
      "Iteration 350, loss = 689089614708.3381\n",
      "\n",
      "index 351\n",
      "index 352\n",
      "index 353\n",
      "index 354\n",
      "index 355\n",
      "index 356\n",
      "index 357\n",
      "index 358\n",
      "index 359\n",
      "index 360\n",
      "Iteration 360, loss = 981926582938.8525\n",
      "\n",
      "index 361\n",
      "index 362\n",
      "index 363\n",
      "index 364\n",
      "index 365\n",
      "index 366\n",
      "index 367\n",
      "index 368\n",
      "index 369\n",
      "index 370\n",
      "Iteration 370, loss = 1331865306555.5422\n",
      "\n",
      "index 371\n",
      "index 372\n",
      "index 373\n",
      "index 374\n",
      "index 375\n",
      "index 376\n",
      "index 377\n",
      "index 378\n",
      "index 379\n",
      "index 380\n",
      "Iteration 380, loss = 388829579135.2558\n",
      "\n",
      "index 381\n",
      "index 382\n",
      "index 383\n",
      "index 384\n",
      "index 385\n",
      "index 386\n",
      "index 387\n",
      "index 388\n",
      "index 389\n",
      "index 390\n",
      "Iteration 390, loss = 518804999431.7162\n",
      "\n",
      "index 391\n",
      "index 392\n",
      "index 393\n",
      "index 394\n",
      "index 395\n",
      "index 396\n",
      "index 397\n",
      "index 398\n",
      "index 399\n",
      "index 400\n",
      "Iteration 400, loss = 264975587426.9162\n",
      "\n",
      "index 401\n",
      "index 402\n",
      "index 403\n",
      "index 404\n",
      "index 405\n",
      "index 406\n",
      "index 407\n",
      "index 408\n",
      "index 409\n",
      "index 410\n",
      "Iteration 410, loss = 329052516372.1378\n",
      "\n",
      "index 411\n",
      "index 412\n",
      "index 413\n",
      "index 414\n",
      "index 415\n",
      "index 416\n",
      "index 417\n",
      "index 418\n",
      "index 419\n",
      "index 420\n",
      "Iteration 420, loss = 216542548068.8478\n",
      "\n",
      "index 421\n",
      "index 422\n",
      "index 423\n",
      "index 424\n",
      "index 425\n",
      "index 426\n",
      "index 427\n",
      "index 428\n",
      "index 429\n",
      "index 430\n",
      "Iteration 430, loss = 1013949539144.9880\n",
      "\n",
      "index 431\n",
      "index 432\n",
      "index 433\n",
      "index 434\n",
      "index 435\n",
      "index 436\n",
      "index 437\n",
      "index 438\n",
      "index 439\n",
      "index 440\n",
      "Iteration 440, loss = 150273118794.2295\n",
      "\n",
      "index 441\n",
      "index 442\n",
      "index 443\n",
      "index 444\n",
      "index 445\n",
      "index 446\n",
      "index 447\n",
      "index 448\n",
      "index 449\n",
      "index 450\n",
      "Iteration 450, loss = 597415355563.7666\n",
      "\n",
      "index 451\n",
      "index 452\n",
      "index 453\n",
      "index 454\n",
      "index 455\n",
      "index 456\n",
      "index 457\n",
      "index 458\n",
      "index 459\n",
      "index 460\n",
      "Iteration 460, loss = 607468806029.5087\n",
      "\n",
      "index 461\n",
      "index 462\n",
      "index 463\n",
      "index 464\n",
      "index 465\n",
      "index 466\n",
      "index 467\n",
      "index 468\n",
      "index 469\n",
      "index 470\n",
      "Iteration 470, loss = 264088085912.2939\n",
      "\n",
      "index 471\n",
      "index 472\n",
      "index 473\n",
      "index 474\n",
      "index 475\n",
      "index 476\n",
      "index 477\n",
      "index 478\n",
      "index 479\n",
      "index 480\n",
      "Iteration 480, loss = 629536311210.4885\n",
      "\n",
      "index 481\n",
      "index 482\n",
      "index 483\n",
      "index 484\n",
      "index 485\n",
      "index 486\n",
      "index 487\n",
      "index 488\n",
      "index 489\n",
      "index 490\n",
      "Iteration 490, loss = 467785323908.3217\n",
      "\n",
      "index 491\n",
      "index 492\n",
      "index 493\n",
      "index 494\n",
      "index 495\n",
      "index 496\n",
      "index 497\n",
      "index 498\n",
      "index 499\n",
      "index 500\n",
      "Iteration 500, loss = 688939542646.4091\n",
      "\n",
      "index 501\n",
      "index 502\n",
      "index 503\n",
      "index 504\n",
      "index 505\n",
      "index 506\n",
      "index 507\n",
      "index 508\n",
      "index 509\n",
      "index 510\n",
      "Iteration 510, loss = 283434738095.0236\n",
      "\n",
      "index 511\n",
      "index 512\n",
      "index 513\n",
      "index 514\n",
      "index 515\n",
      "index 516\n",
      "index 517\n",
      "index 518\n",
      "index 519\n",
      "index 520\n",
      "Iteration 520, loss = 212793180845.9567\n",
      "\n",
      "index 521\n",
      "index 522\n",
      "index 523\n",
      "index 524\n",
      "index 525\n",
      "index 526\n",
      "index 527\n",
      "index 528\n",
      "index 529\n",
      "index 530\n",
      "Iteration 530, loss = 220559910870.1625\n",
      "\n",
      "index 531\n",
      "index 532\n",
      "index 533\n",
      "index 534\n",
      "index 535\n",
      "index 536\n",
      "index 537\n",
      "index 538\n",
      "index 539\n",
      "index 540\n",
      "Iteration 540, loss = 179693323289.4586\n",
      "\n",
      "index 541\n",
      "index 542\n",
      "index 543\n",
      "index 544\n",
      "index 545\n",
      "index 546\n",
      "index 547\n",
      "index 548\n",
      "index 549\n",
      "index 550\n",
      "Iteration 550, loss = 301753568851.5570\n",
      "\n",
      "index 551\n",
      "index 552\n",
      "index 553\n",
      "index 554\n",
      "index 555\n",
      "index 556\n",
      "index 557\n",
      "index 558\n",
      "index 559\n",
      "index 560\n",
      "Iteration 560, loss = 253436828066.6423\n",
      "\n",
      "index 561\n",
      "index 562\n",
      "index 563\n",
      "index 564\n",
      "index 565\n",
      "index 566\n",
      "index 567\n",
      "index 568\n",
      "index 569\n",
      "index 570\n",
      "Iteration 570, loss = 211249630178.7004\n",
      "\n",
      "index 571\n",
      "index 572\n",
      "index 573\n",
      "index 574\n",
      "index 575\n",
      "index 576\n",
      "index 577\n",
      "index 578\n",
      "index 579\n",
      "index 580\n",
      "Iteration 580, loss = 409365520329.6913\n",
      "\n",
      "index 581\n",
      "index 582\n",
      "index 583\n",
      "index 584\n",
      "index 585\n",
      "index 586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 587\n",
      "index 588\n",
      "index 589\n",
      "index 590\n",
      "Iteration 590, loss = 434649606126.5093\n",
      "\n",
      "index 591\n",
      "index 592\n",
      "index 593\n",
      "index 594\n",
      "index 595\n",
      "index 596\n",
      "index 597\n",
      "index 598\n",
      "index 599\n",
      "index 600\n",
      "Iteration 600, loss = 262786223848.6175\n",
      "\n",
      "index 601\n",
      "index 602\n",
      "index 603\n",
      "index 604\n",
      "index 605\n",
      "index 606\n",
      "index 607\n",
      "index 608\n",
      "index 609\n",
      "index 610\n",
      "Iteration 610, loss = 529438041819.4724\n",
      "\n",
      "index 611\n",
      "index 612\n",
      "index 613\n",
      "index 614\n",
      "index 615\n",
      "index 616\n",
      "index 617\n",
      "index 618\n",
      "index 619\n",
      "index 620\n",
      "Iteration 620, loss = 168283934262.1866\n",
      "\n",
      "index 621\n",
      "index 622\n",
      "index 623\n",
      "index 624\n",
      "index 625\n",
      "index 626\n",
      "index 627\n",
      "index 628\n",
      "index 629\n",
      "index 630\n",
      "Iteration 630, loss = 177812621554.1611\n",
      "\n",
      "index 631\n",
      "index 632\n",
      "index 633\n",
      "index 634\n",
      "index 635\n",
      "index 636\n",
      "index 637\n",
      "index 638\n",
      "index 639\n",
      "index 640\n",
      "Iteration 640, loss = 187224458474.5508\n",
      "\n",
      "index 641\n",
      "index 642\n",
      "index 643\n",
      "index 644\n",
      "index 645\n",
      "index 646\n",
      "index 647\n",
      "index 648\n",
      "index 649\n",
      "index 650\n",
      "Iteration 650, loss = 359277604915.9193\n",
      "\n",
      "index 651\n",
      "index 652\n",
      "index 653\n",
      "index 654\n",
      "index 655\n",
      "index 656\n",
      "index 657\n",
      "index 658\n",
      "index 659\n",
      "index 660\n",
      "Iteration 660, loss = 615130628377.5000\n",
      "\n",
      "index 661\n",
      "index 662\n",
      "index 663\n",
      "index 664\n",
      "index 665\n",
      "index 666\n",
      "index 667\n",
      "index 668\n",
      "index 669\n",
      "index 670\n",
      "Iteration 670, loss = 198443913280.8207\n",
      "\n",
      "index 671\n",
      "index 672\n",
      "index 673\n",
      "index 674\n",
      "index 675\n",
      "index 676\n",
      "index 677\n",
      "index 678\n",
      "index 679\n",
      "index 680\n",
      "Iteration 680, loss = 112974174639.1195\n",
      "\n",
      "index 681\n",
      "index 682\n",
      "index 683\n",
      "index 684\n",
      "index 685\n",
      "index 686\n",
      "index 687\n",
      "index 688\n",
      "index 689\n",
      "index 690\n",
      "Iteration 690, loss = 110270429336.5122\n",
      "\n",
      "index 691\n",
      "index 692\n",
      "index 693\n",
      "index 694\n",
      "index 695\n",
      "index 696\n",
      "index 697\n",
      "index 698\n",
      "index 699\n",
      "index 700\n",
      "Iteration 700, loss = 369569340170.9295\n",
      "\n",
      "index 701\n",
      "index 702\n",
      "index 703\n",
      "index 704\n",
      "index 705\n",
      "index 706\n",
      "index 707\n",
      "index 708\n",
      "index 709\n",
      "index 710\n",
      "Iteration 710, loss = 56191433663.2716\n",
      "\n",
      "index 711\n",
      "index 712\n",
      "index 713\n",
      "index 714\n",
      "index 715\n",
      "index 716\n",
      "index 717\n",
      "index 718\n",
      "index 719\n",
      "index 720\n",
      "Iteration 720, loss = 76224272230.7578\n",
      "\n",
      "index 721\n",
      "index 722\n",
      "index 723\n",
      "index 724\n",
      "index 725\n",
      "index 726\n",
      "index 727\n",
      "index 728\n",
      "index 729\n",
      "index 730\n",
      "Iteration 730, loss = 323184400635.0092\n",
      "\n",
      "index 731\n",
      "index 732\n",
      "index 733\n",
      "index 734\n",
      "index 735\n",
      "index 736\n",
      "index 737\n",
      "index 738\n",
      "index 739\n",
      "index 740\n",
      "Iteration 740, loss = 346683438148.2905\n",
      "\n",
      "index 741\n",
      "index 742\n",
      "index 743\n",
      "index 744\n",
      "index 745\n",
      "index 746\n",
      "index 747\n",
      "index 748\n",
      "index 749\n",
      "index 750\n",
      "Iteration 750, loss = 285936846745.2839\n",
      "\n",
      "index 751\n",
      "index 752\n",
      "index 753\n",
      "index 754\n",
      "index 755\n",
      "index 756\n",
      "index 757\n",
      "index 758\n",
      "index 759\n",
      "index 760\n",
      "Iteration 760, loss = 206137566797.9142\n",
      "\n",
      "index 761\n",
      "index 762\n",
      "index 763\n",
      "index 764\n",
      "index 765\n",
      "index 766\n",
      "index 767\n",
      "index 768\n",
      "index 769\n",
      "index 770\n",
      "Iteration 770, loss = 58676452528.5300\n",
      "\n",
      "index 771\n",
      "index 772\n",
      "index 773\n",
      "index 774\n",
      "index 775\n",
      "index 776\n",
      "index 777\n",
      "index 778\n",
      "index 779\n",
      "index 780\n",
      "Iteration 780, loss = 83851695580.9075\n",
      "\n",
      "index 781\n",
      "index 782\n",
      "index 783\n",
      "index 784\n",
      "index 785\n",
      "index 786\n",
      "index 787\n",
      "index 788\n",
      "index 789\n",
      "index 790\n",
      "Iteration 790, loss = 386873275260.3178\n",
      "\n",
      "index 791\n",
      "index 792\n",
      "index 793\n",
      "index 794\n",
      "index 795\n",
      "index 796\n",
      "index 797\n",
      "index 798\n",
      "index 799\n",
      "index 800\n",
      "Iteration 800, loss = 26825159341.6805\n",
      "\n",
      "index 801\n",
      "index 802\n",
      "index 803\n",
      "index 804\n",
      "index 805\n",
      "index 806\n",
      "index 807\n",
      "index 808\n",
      "index 809\n",
      "index 810\n",
      "Iteration 810, loss = 326410709744.2036\n",
      "\n",
      "index 811\n",
      "index 812\n",
      "index 813\n",
      "index 814\n",
      "index 815\n",
      "index 816\n",
      "index 817\n",
      "index 818\n",
      "index 819\n",
      "index 820\n",
      "Iteration 820, loss = 107044141167.8317\n",
      "\n",
      "index 821\n",
      "index 822\n",
      "index 823\n",
      "index 824\n",
      "index 825\n",
      "index 826\n",
      "index 827\n",
      "index 828\n",
      "index 829\n",
      "index 830\n",
      "Iteration 830, loss = 49515372775.7517\n",
      "\n",
      "index 831\n",
      "index 832\n",
      "index 833\n",
      "index 834\n",
      "index 835\n",
      "index 836\n",
      "index 837\n",
      "index 838\n",
      "index 839\n",
      "index 840\n",
      "Iteration 840, loss = 126284382974.9420\n",
      "\n",
      "index 841\n",
      "index 842\n",
      "index 843\n",
      "index 844\n",
      "index 845\n",
      "index 846\n",
      "index 847\n",
      "index 848\n",
      "index 849\n",
      "index 850\n",
      "Iteration 850, loss = 33395254349.2568\n",
      "\n",
      "index 851\n",
      "index 852\n",
      "index 853\n",
      "index 854\n",
      "index 855\n",
      "index 856\n",
      "index 857\n",
      "index 858\n",
      "index 859\n",
      "index 860\n",
      "Iteration 860, loss = 773991892191.1355\n",
      "\n",
      "index 861\n",
      "index 862\n",
      "index 863\n",
      "index 864\n",
      "index 865\n",
      "index 866\n",
      "index 867\n",
      "index 868\n",
      "index 869\n",
      "index 870\n",
      "Iteration 870, loss = 285312003328.5098\n",
      "\n",
      "index 871\n",
      "index 872\n",
      "index 873\n",
      "index 874\n",
      "index 875\n",
      "index 876\n",
      "index 877\n",
      "index 878\n",
      "index 879\n",
      "index 880\n",
      "Iteration 880, loss = 56814500652.2039\n",
      "\n",
      "index 881\n",
      "index 882\n",
      "index 883\n",
      "index 884\n",
      "index 885\n",
      "index 886\n",
      "index 887\n",
      "index 888\n",
      "index 889\n",
      "index 890\n",
      "Iteration 890, loss = 291456254339.5275\n",
      "\n",
      "index 891\n",
      "index 892\n",
      "index 893\n",
      "index 894\n",
      "index 895\n",
      "index 896\n",
      "index 897\n",
      "index 898\n",
      "index 899\n",
      "index 900\n",
      "Iteration 900, loss = 259897634383.8564\n",
      "\n",
      "index 901\n",
      "index 902\n",
      "index 903\n",
      "index 904\n",
      "index 905\n",
      "index 906\n",
      "index 907\n",
      "index 908\n",
      "index 909\n",
      "index 910\n",
      "Iteration 910, loss = 42981831759.7124\n",
      "\n",
      "index 911\n",
      "index 912\n",
      "index 913\n",
      "index 914\n",
      "index 915\n",
      "index 916\n",
      "index 917\n",
      "index 918\n",
      "index 919\n",
      "index 920\n",
      "Iteration 920, loss = 228847129272.6696\n",
      "\n",
      "index 921\n",
      "index 922\n",
      "index 923\n",
      "index 924\n",
      "index 925\n",
      "index 926\n",
      "index 927\n",
      "index 928\n",
      "index 929\n",
      "index 930\n",
      "Iteration 930, loss = 24802597673.7426\n",
      "\n",
      "index 931\n",
      "index 932\n",
      "index 933\n",
      "index 934\n",
      "index 935\n",
      "index 936\n",
      "index 937\n",
      "index 938\n",
      "index 939\n",
      "index 940\n",
      "Iteration 940, loss = 299638111264.8105\n",
      "\n",
      "index 941\n",
      "index 942\n",
      "index 943\n",
      "index 944\n",
      "index 945\n",
      "index 946\n",
      "index 947\n",
      "index 948\n",
      "index 949\n",
      "index 950\n",
      "Iteration 950, loss = 59475968959.8715\n",
      "\n",
      "index 951\n",
      "index 952\n",
      "index 953\n",
      "index 954\n",
      "index 955\n",
      "index 956\n",
      "index 957\n",
      "index 958\n",
      "index 959\n",
      "index 960\n",
      "Iteration 960, loss = 182519388874.6111\n",
      "\n",
      "index 961\n",
      "index 962\n",
      "index 963\n",
      "index 964\n",
      "index 965\n",
      "index 966\n",
      "index 967\n",
      "index 968\n",
      "index 969\n",
      "index 970\n",
      "Iteration 970, loss = 126203036039.0877\n",
      "\n",
      "index 971\n",
      "index 972\n",
      "index 973\n",
      "index 974\n",
      "index 975\n",
      "index 976\n",
      "index 977\n",
      "index 978\n",
      "index 979\n",
      "index 980\n",
      "Iteration 980, loss = 376238821744.7303\n",
      "\n",
      "index 981\n",
      "index 982\n",
      "index 983\n",
      "index 984\n",
      "index 985\n",
      "index 986\n",
      "index 987\n",
      "index 988\n",
      "index 989\n",
      "index 990\n",
      "Iteration 990, loss = 36948236795.5717\n",
      "\n",
      "index 991\n",
      "index 992\n",
      "index 993\n",
      "index 994\n",
      "index 995\n",
      "index 996\n",
      "index 997\n",
      "index 998\n",
      "index 999\n",
      "index 1000\n",
      "Iteration 1000, loss = 287684333659.1429\n",
      "\n",
      "index 1001\n",
      "index 1002\n",
      "index 1003\n",
      "index 1004\n",
      "index 1005\n",
      "index 1006\n",
      "index 1007\n",
      "index 1008\n",
      "index 1009\n",
      "index 1010\n",
      "Iteration 1010, loss = 110490200876.5441\n",
      "\n",
      "index 1011\n",
      "index 1012\n",
      "index 1013\n",
      "index 1014\n",
      "index 1015\n",
      "index 1016\n",
      "index 1017\n",
      "index 1018\n",
      "index 1019\n",
      "index 1020\n",
      "Iteration 1020, loss = 294524859585.7776\n",
      "\n",
      "index 1021\n",
      "index 1022\n",
      "index 1023\n",
      "index 1024\n",
      "index 1025\n",
      "index 1026\n",
      "index 1027\n",
      "index 1028\n",
      "index 1029\n",
      "index 1030\n",
      "Iteration 1030, loss = 53410038799.7411\n",
      "\n",
      "index 1031\n",
      "index 1032\n",
      "index 1033\n",
      "index 1034\n",
      "index 1035\n",
      "index 1036\n",
      "index 1037\n",
      "index 1038\n",
      "index 1039\n",
      "index 1040\n",
      "Iteration 1040, loss = 445358488952.1885\n",
      "\n",
      "index 1041\n",
      "index 1042\n",
      "index 1043\n",
      "index 1044\n",
      "index 1045\n",
      "index 1046\n",
      "index 1047\n",
      "index 1048\n",
      "index 1049\n",
      "index 1050\n",
      "Iteration 1050, loss = 180728085942.9380\n",
      "\n",
      "index 1051\n",
      "index 1052\n",
      "index 1053\n",
      "index 1054\n",
      "index 1055\n",
      "index 1056\n",
      "index 1057\n",
      "index 1058\n",
      "index 1059\n",
      "index 1060\n",
      "Iteration 1060, loss = 146835030749.0587\n",
      "\n",
      "index 1061\n",
      "index 1062\n",
      "index 1063\n",
      "index 1064\n",
      "index 1065\n",
      "index 1066\n",
      "index 1067\n",
      "index 1068\n",
      "index 1069\n",
      "index 1070\n",
      "Iteration 1070, loss = 121394601489.3141\n",
      "\n",
      "index 1071\n",
      "index 1072\n",
      "index 1073\n",
      "index 1074\n",
      "index 1075\n",
      "index 1076\n",
      "index 1077\n",
      "index 1078\n",
      "index 1079\n",
      "index 1080\n",
      "Iteration 1080, loss = 270290792016.4514\n",
      "\n",
      "index 1081\n",
      "index 1082\n",
      "index 1083\n",
      "index 1084\n",
      "index 1085\n",
      "index 1086\n",
      "index 1087\n",
      "index 1088\n",
      "index 1089\n",
      "index 1090\n",
      "Iteration 1090, loss = 635529982917.0957\n",
      "\n",
      "index 1091\n",
      "index 1092\n",
      "index 1093\n",
      "index 1094\n",
      "index 1095\n",
      "index 1096\n",
      "index 1097\n",
      "index 1098\n",
      "index 1099\n",
      "index 1100\n",
      "Iteration 1100, loss = 74261050304.3128\n",
      "\n",
      "index 1101\n",
      "index 1102\n",
      "index 1103\n",
      "index 1104\n",
      "index 1105\n",
      "index 1106\n",
      "index 1107\n",
      "index 1108\n",
      "index 1109\n",
      "index 1110\n",
      "Iteration 1110, loss = 201324839270.9184\n",
      "\n",
      "index 1111\n",
      "index 1112\n",
      "index 1113\n",
      "index 1114\n",
      "index 1115\n",
      "index 1116\n",
      "index 1117\n",
      "index 1118\n",
      "index 1119\n",
      "index 1120\n",
      "Iteration 1120, loss = 129970524140.1148\n",
      "\n",
      "index 1121\n",
      "index 1122\n",
      "index 1123\n",
      "index 1124\n",
      "index 1125\n",
      "index 1126\n",
      "index 1127\n",
      "index 1128\n",
      "index 1129\n",
      "index 1130\n",
      "Iteration 1130, loss = 233103584056.8720\n",
      "\n",
      "index 1131\n",
      "index 1132\n",
      "index 1133\n",
      "index 1134\n",
      "index 1135\n",
      "index 1136\n",
      "index 1137\n",
      "index 1138\n",
      "index 1139\n",
      "index 1140\n",
      "Iteration 1140, loss = 225116550525.2347\n",
      "\n",
      "index 1141\n",
      "index 1142\n",
      "index 1143\n",
      "index 1144\n",
      "index 1145\n",
      "index 1146\n",
      "index 1147\n",
      "index 1148\n",
      "index 1149\n",
      "index 1150\n",
      "Iteration 1150, loss = 222277639315.1405\n",
      "\n",
      "index 1151\n",
      "index 1152\n",
      "index 1153\n",
      "index 1154\n",
      "index 1155\n",
      "index 1156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1157\n",
      "index 1158\n",
      "index 1159\n",
      "index 1160\n",
      "Iteration 1160, loss = 81867136544.7946\n",
      "\n",
      "index 1161\n",
      "index 1162\n",
      "index 1163\n",
      "index 1164\n",
      "index 1165\n",
      "index 1166\n",
      "index 1167\n",
      "index 1168\n",
      "index 1169\n",
      "index 1170\n",
      "Iteration 1170, loss = 473791820287.1033\n",
      "\n",
      "index 1171\n",
      "index 1172\n",
      "index 1173\n",
      "index 1174\n",
      "index 1175\n",
      "index 1176\n",
      "index 1177\n",
      "index 1178\n",
      "index 1179\n",
      "index 1180\n",
      "Iteration 1180, loss = 233001915844.3319\n",
      "\n",
      "index 1181\n",
      "index 1182\n",
      "index 1183\n",
      "index 1184\n",
      "index 1185\n",
      "index 1186\n",
      "index 1187\n",
      "index 1188\n",
      "index 1189\n",
      "index 1190\n",
      "Iteration 1190, loss = 259520439236.5765\n",
      "\n",
      "index 1191\n",
      "index 1192\n",
      "index 1193\n",
      "index 1194\n",
      "index 1195\n",
      "index 1196\n",
      "index 1197\n",
      "index 1198\n",
      "index 1199\n",
      "index 1200\n",
      "Iteration 1200, loss = 476863826471.5348\n",
      "\n",
      "index 1201\n",
      "index 1202\n",
      "index 1203\n",
      "index 1204\n",
      "index 1205\n",
      "index 1206\n",
      "index 1207\n",
      "index 1208\n",
      "index 1209\n",
      "index 1210\n",
      "Iteration 1210, loss = 90460855610.9413\n",
      "\n",
      "index 1211\n",
      "index 1212\n",
      "index 1213\n",
      "index 1214\n",
      "index 1215\n",
      "index 1216\n",
      "index 1217\n",
      "index 1218\n",
      "index 1219\n",
      "index 1220\n",
      "Iteration 1220, loss = 46034393295.4526\n",
      "\n",
      "index 1221\n",
      "index 1222\n",
      "index 1223\n",
      "index 1224\n",
      "index 1225\n",
      "index 1226\n",
      "index 1227\n",
      "index 1228\n",
      "index 1229\n",
      "index 1230\n",
      "Iteration 1230, loss = 272215579344.8854\n",
      "\n",
      "index 1231\n",
      "index 1232\n",
      "index 1233\n",
      "index 1234\n",
      "index 1235\n",
      "index 1236\n",
      "index 1237\n",
      "index 1238\n",
      "index 1239\n",
      "index 1240\n",
      "Iteration 1240, loss = 225490050381.7901\n",
      "\n",
      "index 1241\n",
      "index 1242\n",
      "index 1243\n",
      "index 1244\n",
      "index 1245\n",
      "index 1246\n",
      "index 1247\n",
      "index 1248\n",
      "index 1249\n",
      "index 1250\n",
      "Iteration 1250, loss = 359976068658.8629\n",
      "\n",
      "index 1251\n",
      "index 1252\n",
      "index 1253\n",
      "index 1254\n",
      "index 1255\n",
      "index 1256\n",
      "index 1257\n",
      "index 1258\n",
      "index 1259\n",
      "index 1260\n",
      "Iteration 1260, loss = 75483501800.9029\n",
      "\n",
      "index 1261\n",
      "index 1262\n",
      "index 1263\n",
      "index 1264\n",
      "index 1265\n",
      "index 1266\n",
      "index 1267\n",
      "index 1268\n",
      "index 1269\n",
      "index 1270\n",
      "Iteration 1270, loss = 211304817968.9167\n",
      "\n",
      "index 1271\n",
      "index 1272\n",
      "index 1273\n",
      "index 1274\n",
      "index 1275\n",
      "index 1276\n",
      "index 1277\n",
      "index 1278\n",
      "index 1279\n",
      "index 1280\n",
      "Iteration 1280, loss = 115871875631.7486\n",
      "\n",
      "index 1281\n",
      "index 1282\n",
      "index 1283\n",
      "index 1284\n",
      "index 1285\n",
      "index 1286\n",
      "index 1287\n",
      "index 1288\n",
      "index 1289\n",
      "index 1290\n",
      "Iteration 1290, loss = 47288082398.7053\n",
      "\n",
      "index 1291\n",
      "index 1292\n",
      "index 1293\n",
      "index 1294\n",
      "index 1295\n",
      "index 1296\n",
      "index 1297\n",
      "index 1298\n",
      "index 1299\n",
      "index 1300\n",
      "Iteration 1300, loss = 288904735578.0518\n",
      "\n",
      "index 1301\n",
      "index 1302\n",
      "index 1303\n",
      "index 1304\n",
      "index 1305\n",
      "index 1306\n",
      "index 1307\n",
      "index 1308\n",
      "index 1309\n",
      "index 1310\n",
      "Iteration 1310, loss = 394773225113.5102\n",
      "\n",
      "index 1311\n",
      "index 1312\n",
      "index 1313\n"
     ]
    }
   ],
   "source": [
    "loss_fn = model.customloss\n",
    "# adamvar1 = 1\n",
    "# adamvar2 = 0\n",
    "\n",
    "#print(model.parameters())\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "#1 by 16 \n",
    "# 4 by 4\n",
    "# 16 by 1\n",
    "train(model, loss_fn, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
