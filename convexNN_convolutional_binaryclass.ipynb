{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# import packages \n",
    "import numpy as np\n",
    "import time\n",
    "import cvxpy as cp\n",
    "import torch\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook contains the code for the experiment in figure 11 - plots c, d of the paper\n",
    "# https://arxiv.org/pdf/2101.02429.pdf\n",
    "# The code implements the convex formulation for the two-layer convolutional neural network with global \n",
    "# average pooling for \"binary classification\" (hence, scalar output). The dataset is the fashion-mnist dataset. \n",
    "# For other details, read the explanation for figure 11 - plots c, d of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(12000, 784)\n",
      "(12000, 784) (12000, 1) (2000, 784) (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "# load the fashion mnist dataset\n",
    "# change this directory so it points to the folder where you downloaded the fashion-mnist dataset.\n",
    "directory = '/Users/phalpha/Desktop/Stanford/project/fashion_mnist/data/fashion/' \n",
    "sys.path.insert(1, directory)\n",
    "from fashion_mnist.utils import mnist_reader\n",
    "\n",
    "X_train, y_train = mnist_reader.load_mnist(directory, kind='train')\n",
    "X_test, y_test = mnist_reader.load_mnist(directory, kind='t10k')\n",
    "print(X_train.shape)\n",
    "train_images = X_train.astype(np.float64)\n",
    "train_labels = y_train.astype(np.float64)\n",
    "A = train_images.copy()\n",
    "y = train_labels.copy()\n",
    "\n",
    "inds = np.argwhere(y <= 1)[:,0] # get the first two classes\n",
    "A = A[inds, :]\n",
    "y = y[inds].reshape((inds.shape[0], 1))\n",
    "print(A.shape)\n",
    "n, d = A.shape\n",
    "\n",
    "# test set\n",
    "test_images = X_test.astype(np.float64)\n",
    "test_labels = y_test.astype(np.float64)\n",
    "A_test = test_images.copy()\n",
    "y_test = test_labels.copy()\n",
    "\n",
    "inds_test = np.argwhere(y_test <= 1)[:,0] # get the first two classes\n",
    "A_test = A_test[inds_test, :]\n",
    "y_test = y_test[inds_test].reshape((inds_test.shape[0], 1))\n",
    "\n",
    "A = (A-128)/ 255\n",
    "A_test = (A_test-128) / 255\n",
    "\n",
    "\n",
    "print(A.shape, y.shape, A_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 1, 28, 28)\n",
      "0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, 3100, 3200, 3300, 3400, 3500, 3600, 3700, 3800, 3900, 4000, 4100, 4200, 4300, 4400, 4500, 4600, 4700, 4800, 4900, 5000, 5100, 5200, 5300, 5400, 5500, 5600, 5700, 5800, 5900, 6000, 6100, 6200, 6300, 6400, 6500, 6600, 6700, 6800, 6900, 7000, 7100, 7200, 7300, 7400, 7500, 7600, 7700, 7800, 7900, 8000, 8100, 8200, 8300, 8400, 8500, 8600, 8700, 8800, 8900, 9000, 9100, 9200, 9300, 9400, 9500, 9600, 9700, 9800, 9900, 10000, 10100, 10200, 10300, 10400, 10500, 10600, 10700, 10800, 10900, 11000, 11100, 11200, 11300, 11400, 11500, 11600, 11700, 11800, 11900, "
     ]
    }
   ],
   "source": [
    "# CNN 2D - precompute\n",
    "A_v2 = np.swapaxes(A.reshape(A.shape[0], 1, 28, 28), 2, 3)\n",
    "A_test_v2 = np.swapaxes(A_test.reshape(A_test.shape[0], 1, 28, 28), 2, 3)\n",
    "\n",
    "print(A_v2.shape)\n",
    "stride = 4\n",
    "f = 4 # filter dimension\n",
    "\n",
    "\n",
    "patches_train = torch.nn.functional.unfold(torch.tensor(A_v2), kernel_size=(f,f), stride=stride, padding=0)\n",
    "patches_test = torch.nn.functional.unfold(torch.tensor(A_test_v2), kernel_size=(f,f), stride=stride, padding=0)\n",
    "patches_train = patches_train.numpy()\n",
    "patches_test = patches_test.numpy()\n",
    "\n",
    "K = patches_train.shape[-1]\n",
    "\n",
    "# start pre-computing\n",
    "ff = 1*f**2\n",
    "X_K = np.zeros((n, ff**2+ff+1))\n",
    "for i in range(n):\n",
    "    if i % 100 == 0:\n",
    "        print(i, end=\", \")\n",
    "    for k in range(K):\n",
    "        x_ik = patches_train[i,:,k:k+1]\n",
    "        X_K[i, 0:ff**2] += (1/K * np.matmul(x_ik, x_ik.T).reshape((ff**2)))\n",
    "        X_K[i, ff**2:ff**2+ff] += (1/K * x_ik.reshape((ff)))\n",
    "    X_K[i, ff**2+ff] += 1\n",
    "\n",
    "X_K_save = X_K.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "a, b, c = 0.09, 0.5, 0.47\n",
    "\n",
    "beta = 10**(-6)\n",
    "\n",
    "scs_max_iters = 200000\n",
    "tol = 10**(-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finish pre-computing\n",
    "X_K = X_K_save.copy()\n",
    "X_K[:, 0:ff**2] = a * X_K[:, 0:ff**2]\n",
    "X_K[:, ff**2:ff**2+ff] = b * X_K[:, ff**2:ff**2+ff]\n",
    "X_K[:, ff**2+ff] = c\n",
    "\n",
    "X_KTX_K = np.matmul(X_K.T, X_K)\n",
    "X_KTy = np.matmul(X_K.T, y)\n",
    "y_normsq = np.sum(y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started..\n",
      "time elapsed: 26.05188512802124\n",
      "optimal\n",
      "The optimal value is 259.8190676330244\n",
      "The optimal value is [[259.81906763]]\n"
     ]
    }
   ],
   "source": [
    "# create and solve the optimization problem\n",
    "Z1 = cp.Variable((1*f**2, 1*f**2), symmetric=True)\n",
    "Z2 = cp.Variable((1*f**2, 1))\n",
    "Z4 = cp.Variable((1,1))\n",
    "\n",
    "Z1_prime = cp.Variable((1*f**2, 1*f**2), symmetric=True)\n",
    "Z2_prime = cp.Variable((1*f**2,1))\n",
    "Z4_prime = cp.Variable((1,1))\n",
    "\n",
    "\n",
    "z = cp.vstack((cp.reshape((Z1-Z1_prime), (ff**2,1)), (Z2-Z2_prime), (Z4-Z4_prime)))\n",
    "objective = cp.quad_form(z, X_KTX_K) - 2 * z.T @ X_KTy + y_normsq\n",
    "    \n",
    "objective *= 0.5\n",
    "#objective += (beta*(Z4 + Z4_prime))\n",
    "objective += (beta*(cp.trace(Z1) + cp.trace(Z1_prime)))\n",
    "\n",
    "\n",
    "Z = cp.vstack((cp.hstack((Z1, Z2)), cp.hstack((Z2.T, Z4))))\n",
    "Z_prime = cp.vstack((cp.hstack((Z1_prime, Z2_prime)), cp.hstack((Z2_prime.T, Z4_prime))))\n",
    "constraints = []\n",
    "constraints = [cp.trace(Z1) == Z4]\n",
    "constraints += [cp.trace(Z1_prime) == Z4_prime]\n",
    "constraints += [Z >> 0] + [Z_prime >> 0]\n",
    "\n",
    "prob = cp.Problem(cp.Minimize(objective), constraints)\n",
    "start_time = time.time()\n",
    "print(\"started..\")\n",
    "prob.solve(max_iters=scs_max_iters)#cp.CVXOPT)#solver=cp.SCS) #25000\n",
    "end_time = time.time()\n",
    "time_elapsed_cvx = end_time - start_time\n",
    "print(\"time elapsed: \" + str(time_elapsed_cvx))\n",
    "\n",
    "# Print result.\n",
    "print(prob.status)\n",
    "print(\"The optimal value is\", prob.value)\n",
    "print(\"The optimal value is\", objective.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "costs: 259.81906763313265 47.62188797356929\n",
      "accuracies: 0.9740833333333333 0.971\n",
      "num_neurons_cvx: 34\n"
     ]
    }
   ],
   "source": [
    "# compute accuracies\n",
    "y_hat = np.zeros((A_v2.shape[0], 1))\n",
    "for i in range(A_v2.shape[0]):\n",
    "    patches_ = patches_train[i, :]\n",
    "    Zp = np.matmul((Z1.value-Z1_prime.value), patches_)\n",
    "    quad_term = a * np.sum(np.multiply(patches_, Zp)) / K\n",
    "    lin_term = b * np.sum(np.matmul((Z2.value-Z2_prime.value).T, patches_)) / K\n",
    "    y_hat[i,0] = quad_term + lin_term + c*(Z4.value-Z4_prime.value)\n",
    "y_pred = y_hat > 0.5\n",
    "\n",
    "y_hat_test = np.zeros((A_test_v2.shape[0], 1))\n",
    "for i in range(A_test_v2.shape[0]):\n",
    "    patches_ = patches_test[i, :]\n",
    "    Zp = np.matmul((Z1.value-Z1_prime.value), patches_)\n",
    "    quad_term = a * np.sum(np.multiply(patches_, Zp)) / K\n",
    "    lin_term = b * np.sum(np.matmul((Z2.value-Z2_prime.value).T, patches_)) / K\n",
    "    y_hat_test[i,0] = quad_term + lin_term + c*(Z4.value-Z4_prime.value)\n",
    "y_pred_test = y_hat_test > 0.5\n",
    "\n",
    "\n",
    "noncvx_cost = 0.5*np.sum((y-y_hat)**2) + beta*(Z[-1,-1]+Z_prime[-1,-1]).value\n",
    "noncvx_cost_test = 0.5*np.sum((y_test-y_hat_test)**2) + beta*(Z[-1,-1]+Z_prime[-1,-1]).value\n",
    "\n",
    "\n",
    "training_acc = np.sum(y == y_pred) / y.shape[0]\n",
    "test_acc = np.sum(y_test == y_pred_test) / y_test.shape[0]\n",
    "\n",
    "print(\"costs:\", noncvx_cost, noncvx_cost_test)\n",
    "print(\"accuracies:\", training_acc, test_acc)\n",
    "\n",
    "\n",
    "num_neurons_cvx = np.sum(np.linalg.eig(Z.value)[0] > tol) + np.sum(np.linalg.eig(Z_prime.value)[0] > tol)\n",
    "print(\"num_neurons_cvx: \" + str(num_neurons_cvx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
