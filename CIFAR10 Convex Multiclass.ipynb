{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (3.4.2)\n",
      "Requirement already satisfied: numpy>=1.16 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (7.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "1.8.0\n",
      "Requirement already satisfied: torch==1.8.0 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from torch==1.8.0) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from torch==1.8.0) (3.7.4.3)\n",
      "Requirement already satisfied: opencv-python in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (4.5.2.52)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/phalpha/miniconda3/envs/envtorch/lib/python3.8/site-packages (from opencv-python) (1.19.5)\n",
      "1.8.0\n",
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(torch.__version__)\n",
    "!pip install torch==1.8.0\n",
    "!pip install opencv-python\n",
    "import cv2\n",
    "print(torch.__version__)\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np, numpy.linalg\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float64 # We will be using float throughout this tutorial.\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss.\n",
    "print_every = 100\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = 49000\n",
    "# The torchvision.transforms package provides tools for preprocessing data\n",
    "# # and for performing data augmentation; here we set up a transform to\n",
    "# # preprocess the data by subtracting the mean RGB value and dividing by the\n",
    "# # standard deviation of each RGB value; we’ve hardcoded the mean and std.\n",
    "# transform = T.Compose([\n",
    "#                 T.ToTensor(),\n",
    "#                 T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "#             ])\n",
    "# # We set up a Dataset object for each split (train / val / test); Datasets load\n",
    "# # training examples one at a time, so we wrap each Dataset in a DataLoader which\n",
    "# # iterates through the Dataset and forms minibatches. We divide the CIFAR-10\n",
    "# # training set into train and val sets by passing a Sampler object to the\n",
    "# # DataLoader telling how it should sample from the underlying Dataset.\n",
    "# cifar10_train = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "#                              transform=transform)\n",
    "# loader_train = DataLoader(cifar10_train, batch_size=64,\n",
    "#                           sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "# cifar10_val = dset.CIFAR10('./cs231n/datasets', train=True, download=True,\n",
    "#                            transform=transform)\n",
    "# loader_val = DataLoader(cifar10_val, batch_size=64,\n",
    "#                         sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "# cifar10_test = dset.CIFAR10('./cs231n/datasets', train=False, download=True,\n",
    "#                             transform=transform)\n",
    "# loader_test = DataLoader(cifar10_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _getAplus(A):\n",
    "    eigval, eigvec = np.linalg.eig(A)\n",
    "    Q = np.matrix(eigvec)\n",
    "    xdiag = np.matrix(np.diag(np.maximum(eigval, 0)))\n",
    "    return Q*xdiag*Q.T\n",
    "\n",
    "def _getPs(A, W=None):\n",
    "    W05 = np.matrix(W**.5)\n",
    "    return  W05.I * _getAplus(W05 * A * W05) * W05.I\n",
    "\n",
    "def _getPu(A, W=None):\n",
    "    Aret = np.array(A.copy())\n",
    "    Aret[W > 0] = np.array(W)[W > 0]\n",
    "    return np.matrix(Aret)\n",
    "\n",
    "def nearPD(A, nit=10):\n",
    "    n = A.shape[0]\n",
    "    W = np.identity(n) \n",
    "# W is the matrix used for the norm (assumed to be Identity matrix here)\n",
    "# the algorithm should work for any diagonal W\n",
    "    deltaS = 0\n",
    "    Yk = A.copy()\n",
    "    for k in range(nit):\n",
    "        Rk = Yk - deltaS\n",
    "        Xk = _getPs(Rk, W=W)\n",
    "        deltaS = Xk - Rk\n",
    "        Yk = _getPu(Xk, W=W)\n",
    "    return Yk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters, K = number of patches, P = pooling size, C = output dimension, f = filter size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class custom_multiclass_torch(torch.nn.Module):\n",
    "    def __init__(self, N, P, C, K, f,a,b,c,beta, x_patches_train, x_patches_test):\n",
    "        super(custom_multiclass_torch, self).__init__()\n",
    "\n",
    "        self.N = N\n",
    "        self.P = P\n",
    "        self.C = C \n",
    "        self.K = K\n",
    "        self.f = f \n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.c = c\n",
    "        self.beta = beta\n",
    "        self.x_patches_train = x_patches_train\n",
    "        self.x_patches_test = x_patches_test\n",
    "        #initialize tensor array variables\n",
    "\n",
    "#         self.Z_1_arr_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_1_arr_prime_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_2_arr_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_2_arr_prime_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_4_arr_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_4_arr_prime_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "\n",
    "#         self.Z_arr_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "#         self.Z_arr_prime_train = [[None for j in range(C)]for i in range(K//P) ]\n",
    "        \n",
    "        #print(len(self.Z_1_arr_train))\n",
    "        # set random weights using kaising normalization\n",
    "        \n",
    "        self.Z_1_arr_train = nn.ParameterDict({  })\n",
    "        self.Z_1_arr_prime_train = nn.ParameterDict({})\n",
    "        self.Z_2_arr_train = nn.ParameterDict({})\n",
    "        self.Z_2_arr_prime_train = nn.ParameterDict({})\n",
    "        self.Z_4_arr_train = nn.ParameterDict({})\n",
    "        self.Z_4_arr_prime_train = nn.ParameterDict({})\n",
    "        self.Z_arr_train = {}\n",
    "        self.Z_arr_prime_train = {}\n",
    "        self.x_patches_train = x_patches_train\n",
    "        self.x_patches_test = x_patches_test\n",
    "        for i in range(1,K//P+1):\n",
    "            for j in range(1,C+1):\n",
    "                fan_in = f+1\n",
    "                #w = torch.randn((f+1,f+1), device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "                #w.requires_grad = True\n",
    "                #Z_arr[i][j] = w\n",
    "                #w2 = torch.randn((f+1,f+1), device=device, dtype=dtype) * np.sqrt(2. / fan_in)\n",
    "                #w2.requires_grad = True\n",
    "                #Z_arr_prime_train[i][j] = w2 \n",
    "\n",
    "                #self.test = torch.nn.Parameter(data = torch.randn((f,f), device = device, dtype = dtype), requires_grad = True)\n",
    "#                 self.Z_1_arr_train[i][j] =  torch.nn.Parameter(data = torch.randn((f,f)).to(device), requires_grad = True) \n",
    "#                 self.Z_2_arr_train[i][j]  = torch.nn.Parameter(data = torch.randn((f,1)).to(device),  requires_grad = True) \n",
    "#                 self.Z_4_arr_train[i][j] = torch.nn.Parameter(data = torch.randn((1,1)).to(device),  requires_grad = True) \n",
    "\n",
    "#                 self.Z_1_arr_prime_train[i][j] = torch.nn.Parameter(data =torch.randn((f,f)).to(device),  requires_grad = True) \n",
    "#                 self.Z_2_arr_prime_train[i][j]  = torch.nn.Parameter(data =torch.randn((f,1)).to(device),  requires_grad = True) \n",
    "#                 self.Z_4_arr_prime_train[i][j] = torch.nn.Parameter(data = torch.randn((1,1)).to(device),  requires_grad = True) \n",
    "\n",
    "                \n",
    "#                 self.Z_arr_train[i][j] = torch.vstack((torch.hstack((self.Z_1_arr_train[i][j], self.Z_2_arr_train[i][j])), torch.hstack((torch.transpose(self.Z_2_arr_train[i][j], 0, 1),self.Z_4_arr_train[i][j]))))\n",
    "#                 self.Z_arr_prime_train[i][j] = torch.vstack((torch.hstack((self.Z_1_arr_prime_train[i][j], self.Z_2_arr_prime_train[i][j])), torch.hstack((torch.transpose(self.Z_2_arr_prime_train[i][j], 0, 1),self.Z_4_arr_prime_train[i][j]))))\n",
    "\n",
    "                self.Z_1_arr_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.zeros((3*f**2,3*f**2), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_1_arr_prime_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.zeros((3*f**2,3*f**2), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_2_arr_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.zeros((3*f**2,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_2_arr_prime_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.zeros((3*f**2,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_4_arr_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.zeros((1,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                self.Z_4_arr_prime_train[str(i)+','+str(j)] =  torch.nn.Parameter(data = torch.zeros((1,1), device = device, dtype = dtype), requires_grad = True)\n",
    "                \n",
    "                self.Z_arr_train[str(i)+','+str(j)] = torch.vstack((torch.hstack((self.Z_1_arr_train[str(i)+','+str(j)], self.Z_2_arr_train[str(i)+','+str(j)])), torch.hstack((torch.transpose(self.Z_2_arr_train[str(i)+','+str(j)], 0, 1),self.Z_4_arr_train[str(i)+','+str(j)]))))\n",
    "                self.Z_arr_prime_train[str(i)+','+str(j)] = torch.vstack((torch.hstack((self.Z_1_arr_prime_train[str(i)+','+str(j)], self.Z_2_arr_prime_train[str(i)+','+str(j)])), torch.hstack((torch.transpose(self.Z_2_arr_prime_train[str(i)+','+str(j)], 0, 1),self.Z_4_arr_prime_train[str(i)+','+str(j)]))))\n",
    "                \n",
    "               \n",
    "    #self.Z_1_arr_train = torch.Tensor(self.Z_1_arr_train)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.Z_arr_train = torch.vstack((torch.hstack((self.Z_1_arr_train, self.Z_2_arr_train), torch.hstack(torch.transpose(self.Z_2_arr_train),self.Z_4_arr_train))))\n",
    "        #self.Z_arr_prime_train = torch.vstack((torch.hstack((self.Z_1_arr_prime_train, self.Z_2_arr_prime_train), torch.hstack(torch.transpose(self.Z_2_arr_prime_train),self.Z_4_prime_arr_train))))\n",
    "\n",
    "    def forward(self, i):\n",
    "        \n",
    "        Z_1_new = {}\n",
    "        Z_2_new = {}\n",
    "        Z_4_new = {}\n",
    "        Z_1_prime_new = {}\n",
    "        Z_2_prime_new = {}\n",
    "        Z_4_prime_new = {}\n",
    "        \n",
    "#         for key in self.Z_1_arr_train:\n",
    "#             Z_1_new[key] = 0.5* (self.Z_1_arr_train[key]+ torch.transpose(self.Z_1_arr_train[key], 0, 1))\n",
    "#         for key in self.Z_2_arr_train:\n",
    "#             Z_2_new[key] = 0.5* (self.Z_2_arr_train[key]+ torch.transpose(self.Z_2_arr_train[key], 0, 1))\n",
    "#         for key in self.Z_4_arr_train:\n",
    "#             Z_4_new[key] = 0.5* (self.Z_4_arr_train[key]+ torch.transpose(self.Z_4_arr_train[key], 0, 1))\n",
    "#         for key in self.Z_1_arr_train:\n",
    "#             Z_1_prime_new[key] = 0.5* (self.Z_1_arr_prime_train[key]+ torch.transpose(self.Z_1_arr_prime_train[key], 0, 1))\n",
    "#         for key in self.Z_2_arr_train:\n",
    "#             Z_2_prime_new[key] = 0.5* (self.Z_2_arr_prime_train[key]+ torch.transpose(self.Z_2_arr_prime_train[key], 0, 1))\n",
    "#         for key in self.Z_4_arr_train:\n",
    "#             Z_4_prime_new[key] = 0.5* (self.Z_4_arr_prime_train[key]+ torch.transpose(self.Z_4_arr_prime_train[key], 0, 1))\n",
    "        \n",
    "        \n",
    "        Z_new = {} \n",
    "        Z_new_prime = {}\n",
    "        for key in self.Z_arr_train:\n",
    "            #print(self.Z_arr_train[key].size(), self.Z_arr_train[key].T.size(), torch.eye(3*f**2+1).size())\n",
    "            Z_new[key] = torch.matmul(self.Z_arr_train[key], self.Z_arr_train[key].T)+torch.eye(3*f**2+1)\n",
    "            Z_1_new[key] = Z_new[key][:3*f**2,:3*f**2]\n",
    "            Z_2_new[key] = Z_new[key][3*f**2,:3*f**2]\n",
    "            Z_4_new[key] = Z_new[key][3*f**2,3*f**2]\n",
    "        for key in self.Z_arr_prime_train:\n",
    "            Z_new_prime[key] = torch.matmul(self.Z_arr_prime_train[key], self.Z_arr_prime_train[key].T)+torch.eye(3*f**2+1)\n",
    "            Z_1_prime_new[key] = Z_new[key][:3*f**2,:3*f**2]\n",
    "            Z_2_prime_new[key] = Z_new[key][3*f**2,:3*f**2]\n",
    "            Z_4_prime_new[key] = Z_new[key][3*f**2,3*f**2]\n",
    "        #Sigma_k = torch.mm(Sigma_k, Sigma_k.t())\n",
    "        #Sigma_k.add_(torch.eye(512))\n",
    "\n",
    "        \n",
    "        ypred = torch.zeros((C))\n",
    "        #print(\"index\", i)\n",
    "#         for t in range(1,C+1):\n",
    "#             constant_part = 0\n",
    "#             for k in range(1,K//P+1):\n",
    "#                 constant_part += self.Z_4_arr_train[str(k)+\",\"+str(t)] - self.Z_4_arr_prime_train[str(k)+\",\"+str(t)]\n",
    "\n",
    "#             constant_part *= c\n",
    "\n",
    "#             linear_part = 0\n",
    "#             for k in range(1,K//P+1):\n",
    "#                 for l in range(1,P+1):\n",
    "#                    # print(x_patches[i][(k-1)*P+ l].shape)\n",
    "#                     linear_part += torch.matmul(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0,1),(self.Z_2_arr_train[str(k)+\",\"+str(t)] - self.Z_2_arr_prime_train[str(k)+\",\"+str(t)])).unsqueeze(0)\n",
    "                    \n",
    "#                     #print((self.Z_1_arr_train[str(k)+\",\"+str(t)] - self.Z_1_arr_prime_train[str(k)+\",\"+str(t)]).size())\n",
    "# #                     print((k-1)*P+ l-1, self.x_patches_train[i][(k-1)*P+ l-1].size(), self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1).size())\n",
    "# #                     print((self.Z_2_arr_train[str(k)+\",\"+str(t)] - self.Z_2_arr_prime_train[str(k)+\",\"+str(t)]).size())\n",
    "#             linear_part *= b//P\n",
    "\n",
    "#             quadratic_part = 0\n",
    "#             for k in range(1,K//P+1):\n",
    "#                 for l in range(1,P+1):\n",
    "#                     newpart = torch.matmul(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0, 1),(self.Z_1_arr_train[str(k)+\",\"+str(t)] - self.Z_1_arr_prime_train[str(k)+\",\"+str(t)]))\n",
    "#                     newpart = torch.matmul(newpart, self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2],1))\n",
    "#                     quadratic_part += newpart\n",
    "#                     #print(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0, 1).size())\n",
    "#                     #print(\"second part\")\n",
    "#                     #print((self.Z_1_arr_train[str(k)+\",\"+str(t)] - self.Z_1_arr_prime_train[str(k)+\",\"+str(t)]).size())\n",
    "#                     #print(\"third\")\n",
    "#                     #print(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2],1).size())\n",
    "#             quadratic_part *= a//P\n",
    "            \n",
    "#             #print(quadratic_part, linear_part, constant_part)\n",
    "\n",
    "#             ypred[t-1] = quadratic_part + linear_part + constant_part\n",
    "\n",
    "\n",
    "\n",
    "        for t in range(1,C+1):\n",
    "            constant_part = 0\n",
    "            for k in range(1,K//P+1):\n",
    "                constant_part += Z_4_new[str(k)+\",\"+str(t)] - Z_4_prime_new[str(k)+\",\"+str(t)]\n",
    "\n",
    "            constant_part *= c\n",
    "\n",
    "            linear_part = 0\n",
    "            for k in range(1,K//P+1):\n",
    "                for l in range(1,P+1):\n",
    "                   # print(x_patches[i][(k-1)*P+ l].shape)\n",
    "                    #print(Z_2_new[str(k)+\",\"+str(t)], Z_2_prime_new[str(k)+\",\"+str(t)])\n",
    "                    linear_part += torch.matmul(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0,1),(Z_2_new[str(k)+\",\"+str(t)] - Z_2_prime_new[str(k)+\",\"+str(t)]))\n",
    "\n",
    "                    #print((self.Z_1_arr_train[str(k)+\",\"+str(t)] - self.Z_1_arr_prime_train[str(k)+\",\"+str(t)]).size())\n",
    "#                     print((k-1)*P+ l-1, self.x_patches_train[i][(k-1)*P+ l-1].size(), self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1).size())\n",
    "#                     print((self.Z_2_arr_train[str(k)+\",\"+str(t)] - self.Z_2_arr_prime_train[str(k)+\",\"+str(t)]).size())\n",
    "            linear_part *= b/P\n",
    "\n",
    "            quadratic_part = 0\n",
    "            for k in range(1,K//P+1):\n",
    "                for l in range(1,P+1):\n",
    "                    newpart = torch.matmul(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0, 1),(Z_1_new[str(k)+\",\"+str(t)] - Z_1_prime_new[str(k)+\",\"+str(t)]))\n",
    "                    newpart = torch.matmul(newpart, self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2],1))\n",
    "                    quadratic_part += newpart\n",
    "                    #print(torch.transpose(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2], 1), 0, 1).size())\n",
    "                    #print(\"second part\")\n",
    "                    #print((self.Z_1_arr_train[str(k)+\",\"+str(t)] - self.Z_1_arr_prime_train[str(k)+\",\"+str(t)]).size())\n",
    "                    #print(\"third\")\n",
    "                    #print(self.x_patches_train[i][(k-1)*P+ l-1].view(self.x_patches_train.size()[2],1).size())\n",
    "            quadratic_part *= a/P\n",
    "\n",
    "            #print(quadratic_part.size(), linear_part.size(), constant_part.size())\n",
    "\n",
    "            ypred[t-1] = quadratic_part + linear_part + constant_part\n",
    "        #print(ypred)\n",
    "\n",
    "        \n",
    "        epsilon = 1e-9\n",
    "        \n",
    "        #print(ypred)\n",
    "        #print(ypred)\n",
    "        #ypredmin = torch.min(ypred)\n",
    "        #ypred = ypred + ypredmin + epsilon\n",
    "        #ypred = torch.log(ypred)\n",
    "        \n",
    "        #ypredmax  = torch.max(ypred)\n",
    "        #ypred = ypred - ypredmax\n",
    "        #ypred = torch.log(ypred)\n",
    "        #print(ypred)\n",
    "        softmaxLayer = nn.Softmax(dim  = -1)\n",
    "        #print(ypred)\n",
    "        ypred = softmaxLayer(ypred)\n",
    "        #ypred = softmaxLayer(ypred.view(1, ypred.size()[0]))\n",
    "        #print(ypred)\n",
    "        #return ypred.view(ypred.size()[1])\n",
    "        \n",
    "        \n",
    "        \n",
    "        return ypred\n",
    "\n",
    "    \n",
    "    \n",
    "    def customloss(self, Yhat, y):\n",
    "         #loss = nn.MSELoss()\n",
    "        #objective1 = loss(Yhat, Y)\n",
    "        objective1 = 0.5 * torch.norm(Yhat - y)**2 *N/y.shape[0]\n",
    "\n",
    "        objective2 = 0 \n",
    "\n",
    "        for i in range(1,K//P+1):\n",
    "            for j in range(1,C+1):\n",
    "                objective2 += self.Z_4_arr_train[str(i)+\",\"+str(j)] + self.Z_4_arr_prime_train[str(i)+\",\"+str(j)]\n",
    "            \n",
    "        objective = objective1+objective2\n",
    "\n",
    "        return objective\n",
    "            \n",
    "                  \n",
    "\n",
    "                    \n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cifar10_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# #idx = np.arange(len(X_train))\n",
    "# #np.random.shuffle(idx)\n",
    "\n",
    "# #subset_x_train = x_train[:int(.10*len(idx))]\n",
    "\n",
    "# # X_val = X_test[:X_test.shape[0]//2,:,:,:]\n",
    "# # X_test = X_test[X_test.shape[0]//2:,:,:,:]\n",
    "\n",
    "# # y_val = y_test[:y_test.shape[0]//2,:]\n",
    "# # y_test = y_test[:y_test.shape[0]//2,:]\n",
    "# # print(y_val)\n",
    "\n",
    "# #print(X_train.shape, X_val.shape, X_test.shape)\n",
    "# f = 4\n",
    "# P = 2\n",
    "# C = 10\n",
    "# a,b,c = 1,2,3\n",
    "# beta = 1\n",
    "\n",
    "# #X_train = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_train])\n",
    "# #X_test = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_test])\n",
    "# #X_val = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_val])\n",
    "\n",
    "# #[1 by 4] times [4 by 4] times [4 by 1] = [1 by 1] (scalar)\n",
    "\n",
    "# # train_images = X_train.astype(np.float64)\n",
    "# # train_labels = y_train.astype(np.float64)\n",
    "# # test_images = X_test.astype(np.float64)\n",
    "# # test_labels = y_test.astype(np.float64)\n",
    "# # val_images = X_val.astype(np.float64)\n",
    "# # val_labels = y_val.astype(np.float64)\n",
    "\n",
    "# #train_images_v2 = np.swapaxes(train_images.reshape(train_images.shape[0], 3, 32, 32), 2, 3)\n",
    "# #test_images_v2 = np.swapaxes(test_images.reshape(test_images.shape[0], 3, 32, 32), 2, 3)\n",
    "# #val_images_v2 = np.swapaxes(val_images.reshape(val_images.shape[0],3, 32, 32), 2, 3)\n",
    "\n",
    "# print(train_images_v2.shape, test_images_v2.shape)\n",
    "# patches_train = torch.nn.functional.unfold(torch.tensor(train_images_v2), kernel_size=(f,f), stride=f, padding=0)\n",
    "# patches_test = torch.nn.functional.unfold(torch.tensor(test_images_v2), kernel_size=(f, f), stride=f, padding=0)\n",
    "# patches_val = torch.nn.functional.unfold(torch.tensor(val_images_v2), kernel_size=(f,f), stride=f, padding=0)\n",
    "\n",
    "# print(patches_train.shape)\n",
    "\n",
    "\n",
    "# patches_train = patches_train.permute(0,2,1)\n",
    "# patches_test = patches_test.permute(0,2,1)\n",
    "# patches_val = patches_val.permute(0,2,1)\n",
    "\n",
    "# N = X_train.shape[0]\n",
    "# K = patches_train.shape[1]\n",
    "\n",
    "# print(K, P, C)\n",
    "# Yhat_train =  None\n",
    "# Yhat_test = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3, 32, 32) (100, 3, 32, 32)\n",
      "torch.Size([1000, 48, 64])\n",
      "64 2 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#idx = np.arange(len(X_train))\n",
    "#np.random.shuffle(idx)\n",
    "\n",
    "#subset_x_train = x_train[:int(.10*len(idx))]\n",
    "X_train = X_train[:1000,:,:,:]\n",
    "y_train = y_train[:1000]\n",
    "X_test = X_test[:200,:,:,:]\n",
    "y_test = y_test[:200]\n",
    "\n",
    "X_val = X_test[:X_test.shape[0]//2,:,:,:]\n",
    "X_test = X_test[X_test.shape[0]//2:,:,:,:]\n",
    "\n",
    "y_val = y_test[:y_test.shape[0]//2,:]\n",
    "y_test = y_test[:y_test.shape[0]//2,:]\n",
    "#print(y_val)\n",
    "\n",
    "#print(X_train.shape, X_val.shape, X_test.shape)\n",
    "f = 4\n",
    "P = 2\n",
    "C = 10\n",
    "a,b,c = 1,2,3\n",
    "beta = 1\n",
    "\n",
    "#X_train = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_train])\n",
    "#X_test = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_test])\n",
    "#X_val = np.array([cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) for image in X_val])\n",
    "\n",
    "#[1 by 4] times [4 by 4] times [4 by 1] = [1 by 1] (scalar)\n",
    "\n",
    "#0 0 0 1 0\n",
    "#123123123 111231241 -12342423423424 -234234234 12312312\n",
    "\n",
    "\n",
    "\n",
    "train_images = X_train.astype(np.float64)\n",
    "train_labels = y_train.astype(np.float64)\n",
    "test_images = X_test.astype(np.float64)\n",
    "test_labels = y_test.astype(np.float64)\n",
    "val_images = X_val.astype(np.float64)\n",
    "val_labels = y_val.astype(np.float64)\n",
    "\n",
    "\n",
    "mean_image = np.mean(train_images, axis = 0)\n",
    "train_images -= mean_image\n",
    "test_images -= mean_image\n",
    "val_images -= mean_image\n",
    "\n",
    "\n",
    "\n",
    "train_images_v2 = np.swapaxes(train_images.reshape(train_images.shape[0], 3, 32, 32), 2, 3)\n",
    "test_images_v2 = np.swapaxes(test_images.reshape(test_images.shape[0], 3, 32, 32), 2, 3)\n",
    "val_images_v2 = np.swapaxes(val_images.reshape(val_images.shape[0],3, 32, 32), 2, 3)\n",
    "\n",
    "print(train_images_v2.shape, test_images_v2.shape)\n",
    "patches_train = torch.nn.functional.unfold(torch.tensor(train_images_v2), kernel_size=(f,f), stride=f, padding=0)\n",
    "patches_test = torch.nn.functional.unfold(torch.tensor(test_images_v2), kernel_size=(f, f), stride=f, padding=0)\n",
    "patches_val = torch.nn.functional.unfold(torch.tensor(val_images_v2), kernel_size=(f,f), stride=f, padding=0)\n",
    "\n",
    "print(patches_train.shape)\n",
    "\n",
    "\n",
    "patches_train = patches_train.permute(0,2,1)\n",
    "patches_test = patches_test.permute(0,2,1)\n",
    "patches_val = patches_val.permute(0,2,1)\n",
    "\n",
    "N = X_train.shape[0]\n",
    "K = patches_train.shape[1]\n",
    "\n",
    "print(K, P, C)\n",
    "Yhat_train =  None\n",
    "Yhat_test = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, loss_fn, optimizer, epochs=1):\n",
    "#     model = model.to(device=device) # move the model parameters to CPU/GPU\n",
    "    \n",
    "#     loss_train = []\n",
    "#     accuracies_train = []\n",
    "#     accuracies_val = []\n",
    "\n",
    "#     for e in range(epochs):\n",
    "#         print(train_labels.shape)\n",
    "#         for t, (x, y) in enumerate(loader_train):\n",
    "#             model.train() # put model to training mode\n",
    "#             x = x.to(device=device, dtype=dtype) # move to device, e.g. GPU\n",
    "#             y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "#             scores = model(t)\n",
    "            \n",
    "#             # print(scores.shape)\n",
    "#             # input()\n",
    "\n",
    "#             #loss = F.cross_entropy(scores, y)\n",
    "#             y_hot = torch.zeros(scores.size(), dtype = dtype)\n",
    "            \n",
    "#             y_hot[y] = 1\n",
    "            \n",
    "#             #currect class = 4\n",
    "#             #0 0 0 0 1\n",
    "            \n",
    "#             #0.1 0.5 0.4\n",
    "#             #0 0 1\n",
    "#             #1\n",
    "#             #print(scores, y_hot)\n",
    "\n",
    "#             loss = loss_fn(scores, y_hot)\n",
    "#             loss_train.append(loss)\n",
    "\n",
    "#             # Zero out all of the gradients for the variables which the optimizer\n",
    "#             # will update.\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # This is the backwards pass: compute the gradient of the loss with\n",
    "#             # respect to each  parameter of the model.\n",
    "#             loss.backward()\n",
    "\n",
    "#             # Actually update the parameters of the model using the gradients\n",
    "#             # computed by the backwards pass.\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if t % 10 == 0:\n",
    "#                 print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "#                 accuracies_train.append(check_accuracy(loader_train, model, segment = \"train\"))\n",
    "#                 accuracies_val.append(check_accuracy(loader_val, model, segment = \"val\"))\n",
    "                \n",
    "\n",
    "#     return loss_train, accuracies_train, accuracies_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, epochs=1):\n",
    "    model = model.to(device=device) # move the model parameters to CPU/GPU\n",
    "    \n",
    "    loss_train = []\n",
    "    accuracies_train = []\n",
    "    accuracies_val = []\n",
    "\n",
    "    for e in range(epochs):\n",
    "        #print(train_labels.shape)\n",
    "        for t, (x, y) in enumerate(zip(train_images, train_labels)):\n",
    "            model.train() # put model to training mode\n",
    "            #x = x.to(device=device, dtype=dtype) # move to device, e.g. GPU\n",
    "            #y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(t)\n",
    "            \n",
    "            # print(scores.shape)\n",
    "            # input()\n",
    "\n",
    "            #loss = F.cross_entropy(scores, y)\n",
    "            y_hot = torch.zeros(scores.size(), dtype = dtype)\n",
    "            \n",
    "            y_hot[y] = 1\n",
    "            \n",
    "            #currect class = 4\n",
    "            #0 0 0 0 1\n",
    "            \n",
    "            #0.1 0.5 0.4\n",
    "            #0 0 1\n",
    "            #1\n",
    "            #print(scores, y_hot)\n",
    "\n",
    "            loss = loss_fn(scores, y_hot)\n",
    "            loss_train.append(loss)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % 100 == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                accuracies_train.append(check_accuracy(X_train, y_train, model, segment = \"train\"))\n",
    "                accuracies_val.append(check_accuracy(X_val, y_val, model, segment = \"val\"))\n",
    "                \n",
    "\n",
    "    return loss_train, accuracies_train, accuracies_val\n",
    "\n",
    "                \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_accuracy(loader, model, segment = \"train\"):\n",
    "#     if segment=='train':\n",
    "#         print('Checking accuracy on train set')\n",
    "#     elif segment == \"val\":\n",
    "#         print('Checking accuracy on val set')\n",
    "#     else:\n",
    "#         print('Checking accuracy on test set')\n",
    "#     num_correct = 0\n",
    "#     num_samples = 0\n",
    "#     model.eval()  # set model to evaluation mode\n",
    "#     with torch.no_grad():\n",
    "#         for t, (x, y) in enumerate(loader):\n",
    "#             x = x.to(device=device, dtype=dtype)\n",
    "#             y = y.to(device=device, dtype=torch.long)\n",
    "#             scores = model(t)\n",
    "#             print(scores)\n",
    "#             print(scores.shape)\n",
    "#             print(y)\n",
    "#             max_score_idx = torch.argmax(scores)\n",
    "#             num_correct += int(max_score_idx == y)\n",
    "#             num_samples += 1\n",
    "#         acc = float(num_correct) / num_samples\n",
    "#         print('Got %d / %d correct (%.2f)'% (num_correct, num_samples, 100 * acc))\n",
    "#         return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(X, Y, model, segment = \"train\"):\n",
    "    if segment=='train':\n",
    "        print('Checking accuracy on train set')\n",
    "    elif segment == \"val\":\n",
    "        print('Checking accuracy on val set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(zip(X, Y)):\n",
    "            scores = model(t)\n",
    "            #print(scores)\n",
    "            #print(scores.shape)\n",
    "            #print(y)\n",
    "            max_score_idx = torch.argmax(scores)\n",
    "            y = torch.tensor(y)\n",
    "            addvalue = 1 if (max_score_idx == y) else 0\n",
    "            num_correct += addvalue\n",
    "            num_samples += 1\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)'% (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_multiclass_torch(N, P, C, K, f,a,b,c,beta, patches_train, patches_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for param in model.parameters():\n",
    "    #print(param.shape)\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 45.0000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n",
      "Iteration 100, loss = 38.6000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n",
      "Iteration 200, loss = 32.2000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n",
      "Iteration 300, loss = 25.8000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n",
      "Iteration 400, loss = 19.4000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n",
      "Iteration 500, loss = 13.0000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n",
      "Iteration 600, loss = 6.6000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n",
      "Iteration 700, loss = 0.2000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n",
      "Iteration 800, loss = -6.2000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n",
      "Iteration 900, loss = -12.6000\n",
      "Checking accuracy on train set\n",
      "Got 102 / 1000 correct (10.20)\n",
      "Checking accuracy on val set\n",
      "Got 10 / 100 correct (10.00)\n"
     ]
    }
   ],
   "source": [
    "loss_fn = model.customloss\n",
    "# adamvar1 = 1\n",
    "# adamvar2 = 0\n",
    "\n",
    "#print(model.parameters())\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "\n",
    "#1 by 16 \n",
    "# 4 by 4\n",
    "# 16 by 1\n",
    "loss_train, accuracies_train, accuracies_val = train(model, loss_fn, optimizer, epochs=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Training Accuracy')\n",
    "#print(accuracies_train)\n",
    "plt.plot(accuracies_train)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val Accuracy')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Validation Accuracy')\n",
    "#print(accuracies_val)\n",
    "plt.plot(accuracies_val)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Val Accuracy')\n",
    "#plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title('Training Loss')\n",
    "#print(loss_train)\n",
    "plt.plot(loss_train)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Train Loss')\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "check_accuracy() missing 1 required positional argument: 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-4f08d270d7d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: check_accuracy() missing 1 required positional argument: 'model'"
     ]
    }
   ],
   "source": [
    "check_accuracy(X_test, model, segment = \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
